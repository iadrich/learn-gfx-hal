<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>learn-gfx-hal</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
        <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:500" rel="stylesheet" type="text/css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body class="light">
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { } 
            if (theme === null || theme === undefined) { theme = default_theme; }
            document.body.className = theme;
            document.querySelector('html').className = theme + ' js';
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <ol class="chapter"><li><a href="01_introduction.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li><a href="02_opening_a_window.html"><strong aria-hidden="true">2.</strong> Opening A Window</a></li><li><a href="03_clear_the_window.html"><strong aria-hidden="true">3.</strong> Clear The Window</a></li><li><a href="04_triangle_intro.html"><strong aria-hidden="true">4.</strong> Triangle Intro</a></li><li><a href="05_shaders.html"><strong aria-hidden="true">5.</strong> Shaders</a></li><li><a href="06_textures.html"><strong aria-hidden="true">6.</strong> Textures</a></li></ol>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar" class="menu-bar">
                    <div id="menu-bar-sticky-container">
                        <div class="left-buttons">
                            <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                                <i class="fa fa-bars"></i>
                            </button>
                            <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                                <i class="fa fa-paint-brush"></i>
                            </button>
                            <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                                <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                            </ul>
                            
                            <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                                <i class="fa fa-search"></i>
                            </button>
                            
                        </div>

                        <h1 class="menu-title">learn-gfx-hal</h1> 

                        <div class="right-buttons">
                            <a href="print.html" title="Print this book" aria-label="Print this book">
                                <i id="print-button" class="fa fa-print"></i>
                            </a>
                            
                        </div>
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <a class="header" href="#introduction" id="introduction"><h1>Introduction</h1></a>
<a class="header" href="#what-is-gfx-hal" id="what-is-gfx-hal"><h2>What Is <code>gfx-hal</code></h2></a>
<p>The <a href="https://docs.rs/gfx-hal">gfx-hal</a> crate is a cross platform graphics API
that attempts to be a minimal wrapping of the &quot;modern, low level&quot; graphics APIs
(DX12, Vulkan, and Metal).</p>
<p>To quote Icefox (lead of the GGEZ project):</p>
<blockquote>
<p>I think of Vulkan as basically being GPU assembly language, at least in terms
of level of abstraction. Which is to say, there is very little abstraction: it
gives you the parts that you have to work with, it has nothing stopping you
from doing whatever you feel like with those parts, now go write stuff with
it. No, there's no memory allocator. I just told you to go write stuff, didn't
I? Write it. Comparatively, OpenGL is like GPU Javascript: It starts out
convenient, but it's old, wacky, clunky, weird, has a million evolutionary
versions and odd edge cases, and itâ€™s not really a convenient model for
computation these days. Sure you can make it fast if you try, but you have to
jump through lots of hoops to do so.</p>
</blockquote>
<p>So this will be a <em>very long</em> style of tutorial, because we'll have to be doing
oh-so-many little steps and configurations by hand as we learn to do each new
thing. If that's not your scene then sorry I guess, this tutorial might not be
for you.</p>
<a class="header" href="#requirements" id="requirements"><h2>Requirements</h2></a>
<p>I assume that you have basic familiarity with Rust. So go read <a href="https://doc.rust-lang.org/book/">The Rust
Book</a> if you haven't ever done that.</p>
<p>We will also be touching upon elements of <code>unsafe</code> Rust, and so you should also
read <a href="https://doc.rust-lang.org/nomicon/">The Rustonomicon</a> if you have not.
Actually, that's a mild lie, most of <code>gfx-hal-0.1.0</code> doesn't define any of its
safety limits anyway (not beyond &quot;whatever Vulkan say is okay&quot;), so it's all a
shot in the dark no matter what you do. Even if you're using a backend that
isn't Vulkan.</p>
<p>I don't assume you have any prior graphics programming skills. I sure don't have
much myself. I drew a quad once in OpenGL, but that's it. We'll be learning and
reviewing all that stuff together.</p>
<p>The code all assumes that you're using <strong>Rust 2018</strong>.</p>
<p>I set rustfmt to have 2 space indents and a line limit of 100.</p>
<a class="header" href="#opening-a-window" id="opening-a-window"><h1>Opening A Window</h1></a>
<p>Before we can draw anything, we need a place to draw it. That means we need to
open a window.</p>
<a class="header" href="#initializing-a-window" id="initializing-a-window"><h2>Initializing A Window</h2></a>
<p>To open a window in Rust, you want to use the <a href="https://docs.rs/winit/">winit</a>
crate to get the best cross-platform coverage available. At the time of writing,
the latest version is 0.18. Set up a project for this tutorial however you like
and just add <code>winit</code> to your <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[dependencies]
winit = &quot;0.18&quot;
</code></pre>
<p>The <code>winit</code> crate is what you'd call &quot;mostly stable&quot;. There are small breaking changes
with new versions, but it's usually plain enough to see what the new types or methods
that you need to move to are.</p>
<p>The <a href="https://docs.rs/winit/0.18.0/winit/#building-a-window">crate documentation</a>
goes over the basic steps of building a window:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let events_loop = EventsLoop::new();
let window = WindowBuilder::new()
  .with_title(&quot;Example&quot;)
  .build(&amp;events_loop)
  .expect(&quot;Could not create a window!&quot;);
#}</code></pre></pre>
<p>Of course, the
<a href="https://docs.rs/winit/0.18.0/winit/struct.WindowBuilder.html">WindowBuilder</a>
type has many other methods you might want to use, so be sure to check all
that out.</p>
<a class="header" href="#responding-to-events" id="responding-to-events"><h2>Responding To Events</h2></a>
<p>Once the window is open the user will try to interact with the window. They'll
move the mouse, type keys, click the <code>x</code> in the corner to close it, things like
that. You handle all of this with
<a href="https://docs.rs/winit/0.18.0/winit/struct.EventsLoop.html">EventsLoop</a>.
You can call
<a href="https://docs.rs/winit/0.18.0/winit/struct.EventsLoop.html#method.run_forever">run_forever</a>
with a callback, or
<a href="https://docs.rs/winit/0.18.0/winit/struct.EventsLoop.html#method.poll_events">poll_events</a>
with a callback. In both cases, your callback gets an
<a href="https://docs.rs/winit/0.18.0/winit/enum.Event.html">Event</a>, which is an enum.
Naturally we have to match on that and find the cases we care about. We can discard the
other types. You'll actually get a whole lot of events through <code>winit</code>,
so it's definitely good to ignore most of them if you only care about one or two
event types.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let mut running = true;
while running {
  events_loop.poll_events(|event| match event {
    Event::WindowEvent {
      event: WindowEvent::CloseRequested,
      ..
    } =&gt; running = false,
    _ =&gt; (),
  });
}
#}</code></pre></pre>
<a class="header" href="#pack-it-together" id="pack-it-together"><h2>Pack It Together</h2></a>
<p>We'll have a lot of things floating around as we go along, so we'll want to pack
things together when we can. Winit doesn't care what graphical libs you're using
to draw within the frame, so we can keep just the windowing stuff in its own
struct, apart from any gfx-hal things.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[derive(Debug)]
pub struct WinitState {
  pub events_loop: EventsLoop,
  pub window: Window,
}
#}</code></pre></pre>
<p>Of course, we want to streamline those building steps:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl WinitState {
  /// Constructs a new `EventsLoop` and `Window` pair.
  ///
  /// The specified title and size are used, other elements are default.
  /// ## Failure
  /// It's possible for the window creation to fail. This is unlikely.
  pub fn new&lt;T: Into&lt;String&gt;&gt;(title: T, size: LogicalSize) -&gt; Result&lt;Self, CreationError&gt; {
    let events_loop = EventsLoop::new();
    let output = WindowBuilder::new().with_title(title).with_dimensions(size).build(&amp;events_loop);
    output.map(|window| Self { events_loop, window })
  }
}
#}</code></pre></pre>
<p>And we probably want to go one step farther for our examples and just give a
<code>Default</code> impl that calls <code>new</code> with some default values and then panics if
there's a <code>CreationError</code>.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub const WINDOW_NAME: &amp;str = &quot;Hello Winit&quot;;

impl Default for WinitState {
  /// Makes an 800x600 window with the `WINDOW_NAME` value as the title.
  /// ## Panics
  /// If a `CreationError` occurs.
  fn default() -&gt; Self {
    Self::new(WINDOW_NAME, LogicalSize { width: 800.0, height: 600.0 }).expect(&quot;Could not create a window!&quot;)
  }
}
#}</code></pre></pre>
<a class="header" href="#running-the-program" id="running-the-program"><h2>Running The Program</h2></a>
<p>So far we only have a very tiny main function to look at:</p>
<pre><pre class="playpen"><code class="language-rust">fn main() {
  let mut winit_state = WinitState::default();
  let mut running = true;
  while running {
    winit_state.events_loop.poll_events(|event| match event {
      Event::WindowEvent {
        event: WindowEvent::CloseRequested,
        ..
      } =&gt; running = false,
      _ =&gt; (),
    });
  }
}
</code></pre></pre>
<p>If you run this you get an all white window. Actually, without anything being
drawn to the window, it might instead show all black, or even just garbage pixel
data. It depends on your windowing system.</p>
<p>Also, normally an application would use &quot;Vertical Synchronization&quot; (Vsync) to
slow down the main loop. Without any drawing code we can't use vsync, so the
loop will run as fast as possible and use 100% of the core it's on.</p>
<p>Both things are not good, but this is just a stepping stone and we learn
to draw stuff in the next lesson, so it's fine.</p>
<p>All of the code discussed here is available within the
<a href="https://github.com/gfx-rs/learn-gfx-hal/blob/master/examples/hello_winit.rs">hello_winit</a>
example.</p>
<a class="header" href="#clearing-the-window" id="clearing-the-window"><h1>Clearing The Window</h1></a>
<p>Once you have a window open, the <em>usual</em> next step for a graphics tutorial is to
draw &quot;your first triangle&quot;. You see, the fundamental primitive of 3d graphics is
the triangle. Yes, there are some systems such as the <a href="https://en.wikipedia.org/wiki/Sega_Saturn">Sega
Saturn</a> that use quads instead, but
in all the modern systems you'll find it's going to be triangles. Even a quad is
just two triangles, when you think about it. With enough math and enough
parallel processing you can do anything you want with triangles.</p>
<ul>
<li>Skyrim? Triangles.</li>
<li>Breath of The Wild? Has a few more triangles than Skyrim.</li>
<li>Super Smash Bros? Just a whole lot of triangles.</li>
</ul>
<p>We'll be covering triangles <em>quite</em> a bit. However, in the context of <code>gfx-hal</code>,
which is like 97% &quot;whatever Vulkan does&quot;, even if you're <em>not</em> using the Vulkan
backend, there's a great <em>many</em> steps of setup involved between &quot;a window that
draws nothing&quot; and &quot;a window that draws one triangle&quot;.</p>
<p>In fact the <a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/">official gfx-hal docs</a>
specifically give us a warning about this. The top level docs are so short I can
include all three sentences right here for dramatic effect:</p>
<blockquote>
<p>Low-level graphics abstraction for Rust. Mostly operates on data, not types.
Designed for use by libraries and higher-level abstractions only.</p>
</blockquote>
<p>There are basically no defaults provided. We have to list out every single
little step of the entire configuration process. I mean they convert C types
into Rust types for us, but it's still very &quot;do it yourself&quot;. That's <em>cool</em> if
you actually care about defining it all (which you will some day, I'm sure, or
you wouldn't be reading this right now), but it's also <em>long</em> when you're
starting out and want to get something on the screen.</p>
<p>Since going all the way to &quot;drawing a triangle&quot; might end up feeling like too
much at once, we'll stop this lesson at an intermediate step. Remember how our
<code>winit</code> window from last lesson didn't refresh itself properly? We can fix just
that much and then stop there. That <em>alone</em> will cover a surprising amount of
ground.</p>
<a class="header" href="#outline-our-target-api" id="outline-our-target-api"><h2>Outline Our Target API</h2></a>
<p>So, in the first lesson we had <code>WinitState</code> and it just had two public fields.
There's not much there, it's all safe code, and it's not the focus of our
lessons, so that's fine. I mean I guess you could pair up the wrong <code>EventLoop</code>
with the wrong <code>Window</code> or something, but two public fields is good enough.</p>
<p>With <code>gfx-hal</code> it is <em>wildly</em> the opposite situation. We're going to be juggling
a dozen or more things at once, and most of them are <strong>very</strong> unsafe things that
must be handled with extreme care. <code>gfx-hal</code>, at its core, is about directing a
pile of DMA units and a hyper-SIMD co-processor with all safety checks left in
&quot;up to you&quot; mode. That's <em>about</em> as unsafe as it gets. Not only do we want a
<code>HalState</code> type, we want to expose <em>nothing</em> that's inside of it, because it's
all a giant pile of sharp and dangerous things. We want to wrap all that up,
then offer a very small, well curated, semantically meaningful set of operations
that the outside world can access.</p>
<p>Sure sounds like API Design. There's so much that could be said about API
design. Let's keep it short:</p>
<ul>
<li>Always, <em>Always</em>, <strong><em>Always</em></strong> <a href="https://caseymuratori.com/blog_0025">write the usage code
first.</a></li>
</ul>
<p>Even before we know <em>any details about how <code>gfx-hal</code> works</em>, we're going to just
write out how we <em>think</em> we should be able to use it. How we think it's be
easiest to use. Once it's built we will be calling the methods a lot more than
we'll be implementing the methods, so unless we end up with some sort of
performance disaster or impossible requirement we'll keep the exterior simple
even if it means the interior might end up a little more complex.</p>
<p>So what's our <em>usage</em> of the <code>HalState</code> type look like?</p>
<p>There's lots of answers you could have to that question. Really, there are.
Obviously since I'm writing this we're going to be using what I came up with,
but if you think you can get a better solution you should try it out. I'll try
to explain my thinking as best as I can, and hopefully you'll agree with me.</p>
<a class="header" href="#initialization" id="initialization"><h3>Initialization</h3></a>
<p>We already have <code>WinitState</code>, we're going to want <code>HalState</code> too. Clearly the
<code>WinitState</code> can be made before the <code>HalState</code> (since we did it last lesson).</p>
<p>We'll also want to have a <code>LocalState</code>, and that's the grab bag of everything
else in the program. If you're doing a game or a simulation or something that's
your <code>GameState</code> or <code>World</code> or whatever you wanna call the type.</p>
<p>So far the code outline looks like this:</p>
<pre><pre class="playpen"><code class="language-rust">fn main(){
  let mut winit_state = WinitState::default();
  let mut hal_state = HalState::default();
  let mut local_state = LocalState::default();
  // MAIN LOOP
  // CLEANUP
}
</code></pre></pre>
<p>Except, when you think about it, the way that <code>gfx-hal</code> initializes itself
~~probably~~ definitely depends on the <code>Window</code> it's going to draw within. It
can't be totally default with no inputs. We need a <code>HalState</code> initialization
method that takes a <code>Window</code> reference. The default name for any initialization
method in Rust is just <code>new</code>, and I can't think of a better name to use, so
we'll go with that.</p>
<pre><pre class="playpen"><code class="language-rust">fn main(){
  let mut winit_state = WinitState::default();
  let mut hal_state = HalState::new(&amp;winit_state.window);
  let mut local_state = LocalState::default();
  // MAIN LOOP
  // CLEANUP
}
</code></pre></pre>
<p>Also, of course, our local variables might depend on all sorts of things in some
sort of application specific way. That part is up to you.</p>
<a class="header" href="#main-loop" id="main-loop"><h3>Main Loop</h3></a>
<p>Once things are all initialized and ready we go into the &quot;main loop&quot; part of the
program.</p>
<p><strong>Digression:</strong> Video is really just a series of still pictures. You show one after
the other, very quickly, and a human brain interprets the existence of movement
where none &quot;really&quot; exists. Each picture is a &quot;frame&quot;, and how quickly you go
from one frame to the next is the &quot;frames per second&quot; (fps). The minimum fps for
apparent movement is actually quite modest, you only need <a href="https://en.wikipedia.org/wiki/Frame_rate#Human_vision">about
12</a>. More is better of
course, the movement appears smoother the more fps you have. People have been
animating for a long time and there's all sorts of standards by now, but on a
computer you're usually expected to be drawing at about 60fps for &quot;good&quot; quality
animation and 30fps for &quot;I guess that's okay for something made in Unity&quot;
quality animation.</p>
<p><strong>Back to code:</strong> The implication here is that each pass through our main loop
will be one frame of display. We gather up the input for that frame, adjust our
local variables according to the input (eg: in a game you might move the player a tiny
bit, or whatever change), and then render the new state of the world into a frame that
gets shown to the user. Something like this:</p>
<pre><pre class="playpen"><code class="language-rust">fn main(){
  let winit_state = WinitState::default();
  let hal_state = HalState::new(&amp;winit_state.window);
  let mut local_state = LocalState::default();
  loop {
    let inputs = UserInput::poll_events_loop(&amp;mut winit_state.event_loop);
    if inputs.end_requested {
      break;
    }
    local_state.update_from_input(inputs);
    do_the_render(&amp;mut hal_state, &amp;local_state);
  }
  // CLEANUP
}
</code></pre></pre>
<p>This should look fairly familiar after what we did in the first lesson.</p>
<p>You may be wondering why the <code>do_the_render</code> function is taking a <code>&amp;mut HalState</code> as the first argument, instead of having it be a <code>&amp;mut self</code> method on
the <code>HalState</code> type. Well, I'm not sure it's the perfect decision, but we're
going to <em>try</em> and keep our <code>HalState</code> and <code>LocalState</code> as totally separate as
we can.</p>
<ul>
<li>If <code>HalState</code> doesn't know anything about the <code>LocalState</code> then it's a lot
more likely to focus on reusable drawing operations, and we'll be a lot more
likely to have something we can reuse in future situations (including
&quot;practical&quot; situations beyond just this tutorial series).</li>
<li>Similarly, if <code>LocalState</code> doesn't know about <code>HalState</code> then it's easier for
it to focus on the &quot;business logic&quot; without worrying about anything else. We
could even run the <code>LocalState</code> <em>without graphics at all</em> (sometimes called a
&quot;headless&quot; mode), which can be nice if you want to do CI tests, or hook it to
a server people connect to, or any other unexpected use.</li>
</ul>
<p>It can often be <em>tempting</em> to make everything into a method on some type, but
that's an urge we need to resist in this situation.</p>
<a class="header" href="#what-does-do_the_render-actually-do" id="what-does-do_the_render-actually-do"><h3>What Does <code>do_the_render</code> Actually Do?</h3></a>
<p>I cheated a bit there, because I wrote down a call to <code>do_the_render</code> without
actually saying <em>what</em> it's doing on the inside. That's the part we care about
the most! That's how we know what our <code>HalState</code> API needs to look like.</p>
<p>For this lesson, all we do is clear the screen. That sounds simple enough. Later
lessons will add more, but this is our starting point.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn do_the_render(hal: &amp;mut HalState, locals: &amp;LocalState) {
  hal.draw_clear_frame(locals.color());
}
#}</code></pre></pre>
<p>That looks okay at first, but there might be some sort of error that happens
during rendering. Nothing inside <code>do_the_render</code> particularly knows about how to
handle an error, so we'll just pass that back up the stack.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn do_the_render(hal: &amp;mut HalState, locals: &amp;LocalState) -&gt; Result&lt;(), &amp;str&gt; {
  hal.draw_clear_frame(locals.color())
}
#}</code></pre></pre>
<p>And then in <code>main</code> I guess we can just... log the error and quit? It's not ideal
for the program to shut itself down unexpectedly, but we don't really have a
backup strategy at the moment. In a more advanced situation the error might be
from the user trying to switch graphics settings or something, so you could
automatically switch back to the previous settings in that case. Depends on the
program, and the error.</p>
<p>Also, in a full program you'd want to use a proper error enum, but we don't know
what all our possible errors are, so we'll just use string literals for now.</p>
<p>Anyway, now things look more like this:</p>
<pre><pre class="playpen"><code class="language-rust">fn main(){
  let winit_state = WinitState::default();
  let hal_state = HalState::new(&amp;winit_state.window);
  let mut local_state = LocalState::default();
  loop {
    let inputs = UserInput::poll_events_loop(&amp;mut winit_state.events_loop);
    if inputs.end_requested {
      break;
    }
    local_state.update_from_input(inputs);
    if let Err(e) = do_the_render(&amp;mut hal_state, &amp;local_state) {
      error!(&quot;Rendering Error: {:?}&quot;, e);
      break;
    }
  }
  // CLEANUP
}
</code></pre></pre>
<a class="header" href="#cleanup" id="cleanup"><h3>Cleanup</h3></a>
<p>Usually when working with &quot;foreign&quot; data, anything that comes from outside of
Rust, you have to consider the possibility that you'll have to manually do some
cleanup work. <code>gfx-hal</code> is no different. Not only do we need to clean things up
to avoid leaks when we're done, we need to clean up in the exactly correct
order. The backend code can segfault your process just by you not shutting it
down properly.</p>
<p>How do we expose this in our API?</p>
<p>We <em>don't</em>.</p>
<p>I'm not saying that we <em>ignore</em> the subject of cleanup, that would be foolish,
but I am saying that we should keep all of it entirely within the <code>HalState</code>
type. Things are smoothest for the user when they can just let a type drop away
without a care, and we're going to try and allow for such an easy use
experience. Mostly what this means is that we won't want to have any &quot;getter&quot;
methods that let an outside user move out anything that needs to be manually
destroyed later. If they want to check the value of a number or maybe even get a
<code>&amp;mut</code> to some that's fine, but anything that needs to be explicitly cleaned up
we can't let out of our control.</p>
<p>Now we can see our final outline:</p>
<pre><pre class="playpen"><code class="language-rust">fn main(){
  let winit_state = WinitState::default();
  let hal_state = HalState::new(&amp;winit_state.window);
  let mut local_state = LocalState::default();
  loop {
    let inputs = UserInput::poll_events_loop(&amp;mut winit_state.event_loop);
    if inputs.end_requested {
      break;
    }
    local_state.update_from_input(inputs);
    if let Err(e) = do_the_render(&amp;mut hal_state, &amp;local_state) {
      error!(&quot;Rendering Error: {:?}&quot;, e);
      break;
    }
  }
}
</code></pre></pre>
<p>Will we achieve this? Hard to say without trying.</p>
<a class="header" href="#activate-logging-powers" id="activate-logging-powers"><h2>Activate Logging Powers</h2></a>
<p>As you write for <code>gfx-hal</code>, you'll definitely write stuff that's wrong. That's
just how it goes, no shame in it. There's so many rules and details that even
the <code>gfx-rs</code> team members don't know all of it all the time. They look at the
Vulkan spec to verify the rules just like anyone else has to. Thankfully, we can
avoid having too many bugs quietly creep into things by logging what's going on
inside the program and hopefully something will show up in the logs to explain
the problem when there is a problem.</p>
<a class="header" href="#the-log-crate" id="the-log-crate"><h3>The <code>log</code> Crate</h3></a>
<p>If you've ever done logging before you know that usually there's a &quot;logging
facade&quot; which defines a way to write log messages that libraries use, and then
there's an actual logging implementation that a binary will activate at the
start of a process to receive logging messages and deal with them. Rust is no
different.</p>
<p>You use the <a href="https://docs.rs/log">log</a> crate to write a logging message. You use
<a href="https://docs.rs/log/0.4.6/log/#available-logging-implementations">a logging implementation of
choice</a> to
actually process those logging messages. The actual macros for logging are just
like how <code>println!</code> works, but instead of being called <code>println!</code> there's one
macro for each &quot;level&quot; of logging. From most important to least important it
goes: <code>error!</code>, <code>warn!</code>, <code>info!</code>, <code>debug!</code> and <code>trace!</code>. Different logging
implementations let you limit the levels that actually get logged, and the
logging crate has features to restrict what logging messages even get compiled
in (so you can compile out all logging in release mode or whatever). It's a
whole huge thing you can really dig through if you want.</p>
<p>I don't want to. I want to not have any fuss. So we'll use
<a href="https://crates.io/crates/simple_logger">simple_logger</a> which is exactly as easy
as it sounds. You write one line, once, and then logging messages just go to
<code>stdout</code> or <code>stderr</code>.</p>
<p>First we add things to our <code>Cargo.toml</code> file.</p>
<pre><code class="language-toml">[dependencies]
log = &quot;0.4.0&quot;
simple_logger = &quot;1.0&quot;
winit = &quot;0.18&quot;
</code></pre>
<p>And then we turn on the <code>simple_logger</code> in main before we do anything else:</p>
<pre><pre class="playpen"><code class="language-rust">fn main() {
  simple_logger::init().unwrap();
  // ...
</code></pre></pre>
<p>And now we'll see anything that someone wanted to log. If we want to do our own
logging that's easy too:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[allow(unused_imports)]
use log::{error, warn, info, debug, trace};
#}</code></pre></pre>
<a class="header" href="#lunarg-vulkan-sdk" id="lunarg-vulkan-sdk"><h3>LunarG Vulkan SDK</h3></a>
<p>Next you'll also want some tools that <em>aren't</em> strictly Rust related (shocking,
I know).</p>
<p>The <a href="https://vulkan.lunarg.com/sdk/home">LunarG Vulkan SDK</a> is a free set of
tools for all major operating systems. Once you install the SDK, if you're using
the <code>gfx-backend-vulkan</code> crate as your <code>gfx-hal</code> backend it'll log any
validation errors when <code>debug_assertions</code> are on. You don't need to do any
special setup, it just conveniently happens for you.</p>
<p>Unfortunately, when testing with other backends you're much more &quot;on your own&quot;,
but some help is still better than zero help. You can set up Metal validation,
and I'll update here just as soon as one of the gfx team members with a mac
updates me on what to say.</p>
<a class="header" href="#adding-in-gfx-hal-and-a-backend" id="adding-in-gfx-hal-and-a-backend"><h2>Adding In <code>gfx-hal</code> And A Backend</h2></a>
<p>Adding <code>gfx-hal</code> to our <code>Cargo.toml</code> file comes in two parts. There's <code>gfx-hal</code>,
and also we need an actual &quot;backend&quot; that provides a specific implementation of
the types and operations that <code>gfx-hal</code> defines.</p>
<a class="header" href="#configuring-cargo" id="configuring-cargo"><h3>Configuring Cargo</h3></a>
<p>We want to keep the backend selection as easy to swap as possible. Normally this
is done at compile time, since there's only about one good backend per OS
anyway, and it keeps things simpler than trying to select a backend at startup.
The standard idiom for how to do this looks something like:</p>
<pre><code class="language-toml">[features]
default = []
metal = [&quot;gfx-backend-metal&quot;]
dx12 = [&quot;gfx-backend-dx12&quot;]
vulkan = [&quot;gfx-backend-vulkan&quot;]

[dependencies]
log = &quot;0.4.0&quot;
simple_logger = &quot;1.0&quot;
winit = &quot;0.18&quot;
gfx-hal = &quot;0.1&quot;
arrayvec = &quot;0.4&quot;

[dependencies.gfx-backend-vulkan]
version = &quot;0.1&quot;
optional = true

[target.'cfg(target_os = &quot;macos&quot;)'.dependencies.gfx-backend-metal]
version = &quot;0.1&quot;
optional = true

[target.'cfg(windows)'.dependencies.gfx-backend-dx12]
version = &quot;0.1&quot;
optional = true
</code></pre>
<p>If you want the Rust Language Server (RLS) to play nice with the various
optional features you must tell it which one to use for its compilations. You
could specify a default feature, but that's not quite elegant. If you're using
VS Code with the RLS plugin you can instead make a <code>.vscode/settings.json</code> file
in your project folder, and then in there place a setting for the feature you
want it to use for RLS runs. Something like this:</p>
<pre><code class="language-json">{
  &quot;rust.features&quot;: [
    &quot;dx12&quot;
  ]
}
</code></pre>
<p>If you're using RLS with some editor besides VS Code I'm afraid I don't know the
details of how you tell RLS to use a particular feature, but you probably can.
Consult your plugin docs, and such.</p>
<a class="header" href="#configuring-the-code" id="configuring-the-code"><h3>Configuring The Code</h3></a>
<p>Over inside our main file we won't actually be importing too much from the
backends, but we'll place some conditional <code>use</code> statements so that they're
always aliased to the same name, regardless of what one we're using.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[cfg(feature = &quot;dx12&quot;)]
use gfx_backend_dx12 as back;
#[cfg(feature = &quot;metal&quot;)]
use gfx_backend_metal as back;
#[cfg(feature = &quot;vulkan&quot;)]
use gfx_backend_vulkan as back;
#}</code></pre></pre>
<a class="header" href="#any-other-backend-options" id="any-other-backend-options"><h3>Any Other Backend Options?</h3></a>
<p>There <em>are</em> other backend options that we haven't considered:</p>
<ul>
<li><a href="https://crates.io/crates/gfx-backend-empty">gfx-backend-empty</a> does nothing
but provide the required implementations as empty structs and do-nothing
methods and similar. It's mostly used in the rustdoc examples for <code>gfx-hal</code>,
so that they can check that doctests compile properly. You might also use this
with RLS I guess, but since you'll also need a real backend compiled to run
any code, you might as well make RLS use your real backend.</li>
<li><a href="https://crates.io/crates/gfx-backend-gl">gfx-backend-gl</a> lets you target
OpenGL 2.1+ and OpenGL ES2+. You'd probably use this if you wanted to run
inside a webpage, or perhaps on a Raspberry Pi (which has OpenGL ES2 drivers,
but not Vulkan), or anything else where you can't pick one of the &quot;main&quot;
options. Unfortunately, the GL backend is actually a little busted at the
moment. The biggest snag is that webpages and desktop apps have rather
different control flow, so it's hard to come up with a unified API. Work is
being done, and hopefully soon I'll be able to recommend the GL backend.</li>
</ul>
<a class="header" href="#also-arrayvec" id="also-arrayvec"><h3>Also <code>arrayvec</code></h3></a>
<p>As you might have noticed, we're going to be using
<a href="https://docs.rs/arrayvec">arrayvec</a> later on for the <code>ArrayVec</code> type. I don't
want to come back to <code>Cargo.toml</code> later, so we can just mention it now.</p>
<p><code>ArrayVec</code> works basically just like <code>Vec</code> but it's backed by an array on the
stack, not a data blob on the heap, so it can't resize, but it also doesn't need
a heap allocation to construct. We'll be using it during our draw code so that
we can call a few critical functions without doing a heap allocation each frame.
The functions in question have some weird generic bounds that work out for <code>Vec</code>
and <code>ArrayVec</code> and similar, but not for arrays themselves. Generics just be like
that sometimes.</p>
<a class="header" href="#implementing-draw_clear_frame" id="implementing-draw_clear_frame"><h1>Implementing <code>draw_clear_frame</code></h1></a>
<p>You might think that we'd start by learning how to initialize things, but
actually our core goal is clearing the screen. Anything else that we do,
including the initialization, is <em>only in service to that goal</em>. So first we'll
focus on our core goal, then we'll see what we need for that, and then we'll see
what we need for <em>that</em>, until eventually we stop needing to have already done
something else.</p>
<p>We'll be filling in this method:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl HalState {
  pub fn draw_clear_frame(&amp;mut self, color: [f32; 4]) -&gt; Result&lt;(), &amp;'static str&gt; {
    unimplemented!()
  }
}
#}</code></pre></pre>
<a class="header" href="#commandqueue" id="commandqueue"><h2>CommandQueue</h2></a>
<p>The heart of it all is that we want to be able to safely call
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/queue/struct.CommandQueue.html#method.submit">CommandQueue::submit</a>,
which submits a list of work which we define in a <code>CommandBuffer</code> to the GPU (in
this case just clearing the image), and then we call
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/trait.Swapchain.html#method.present">Swapchain::present</a>,
which instructs the GPU to wait until the CommandQueue work is done and
&quot;present&quot; the completed image into the Swapchain.</p>
<p><em>Exactly</em> what happens at that point depends on how you've configured the
Swapchain, which we'll talk about in the initialization section. The important
part to remember here is that <code>Swapchain::present</code> is effectively a
<strong>non-blocking</strong> call. If you're used to using OpenGL you might expect <code>present</code>
to be the point where your loop halts until Vsync, but with <code>gfx-hal</code> anything
that makes the CPU wait on the GPU is controlled via &quot;Fences&quot; (which we'll see
in a moment), and that doesn't include <code>present</code>.</p>
<a class="header" href="#submit" id="submit"><h3><code>submit</code></h3></a>
<p>The actual type of the <code>submit</code> method is <em>super generic</em> which means that it
reads like a pile of space runes:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub unsafe fn submit&lt;'a, T, Ic, S, Iw, Is&gt;(
    &amp;mut self, 
    submission: Submission&lt;Ic, Iw, Is&gt;, 
    fence: Option&lt;&amp;B::Fence&gt;
)
where
    T: 'a + Submittable&lt;B, C, Primary&gt;,
    Ic: IntoIterator&lt;Item = &amp;'a T&gt;,
    S: 'a + Borrow&lt;B::Semaphore&gt;,
    Iw: IntoIterator&lt;Item = (&amp;'a S, PipelineStage)&gt;,
    Is: IntoIterator&lt;Item = &amp;'a S&gt;,
#}</code></pre></pre>
<p>Gross, right? Let's cut out those generics and look again:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub unsafe fn submit(&amp;mut self, submission: Submission, fence: Option&lt;&amp;B::Fence&gt;)
#}</code></pre></pre>
<p>Okay that's <em>way</em> easier to look at and understand. It's just a rustified
version of
<a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/vkQueueSubmit.html">vkQueueSubmit</a>.
Which doesn't mean anything to you right now because we're just starting, but
like I said at the top: if the <code>gfx-hal</code> docs aren't clear on their semantics,
you can usually assume that Vulkan semantics apply.</p>
<ul>
<li>We <code>submit</code> a <code>Submission</code> into the <code>CommandQueue</code>. Instead of giving a count
and a pointer to an array of &quot;VkSubmitInfo&quot;, we give a single <code>Submission</code>,
which is itself composed of <code>IntoIterator</code> things that I assume get iterated
over. <em>Unfortunately</em>, since each backend has to handle the info in slightly
different ways, we have to pay for that cross-platform benefit by things
sometimes being a little less clear on our end.</li>
<li>We optionally give a &quot;fence&quot; which gets &quot;signalled&quot; once all of the submitted
command buffers have completed execution. We'll talk about that in a moment.</li>
</ul>
<a class="header" href="#present" id="present"><h3><code>present</code></h3></a>
<p>The <code>present</code> method looks like this</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
unsafe fn present&lt;'a, C, S, Iw&gt;(
    &amp;'a self, 
    present_queue: &amp;mut CommandQueue&lt;B, C&gt;, 
    image_index: SwapImageIndex, 
    wait_semaphores: Iw
) -&gt; Result&lt;(), ()&gt;
where
    Self: 'a + Sized + Borrow&lt;B::Swapchain&gt;,
    C: Capability,
    S: 'a + Borrow&lt;B::Semaphore&gt;,
    Iw: IntoIterator&lt;Item = &amp;'a S&gt;, 
#}</code></pre></pre>
<p>And if we cut out the extra stuff:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
unsafe fn present(
    &amp;self, 
    present_queue: &amp;mut CommandQueue&lt;B, C&gt;,
    image_index: SwapImageIndex,
    wait_semaphores: Iw) -&gt; Result&lt;(), ()&gt;
#}</code></pre></pre>
<p>So <code>present</code> takes a <code>&amp;mut</code> to our <code>CommandQueue</code>, a target index within the
Swapchain to present to, and a semaphore to wait on before actually presenting
the image. This works like
<a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/vkQueuePresentKHR.html">vkQueuePresentKHR</a>.
When we call <code>submit</code>, one of the Submission elements is going to be a semaphore
to signal when the rendering is done. When we call <code>present</code> we give it that
same semaphore to wait on before presenting the image, so that the user only
sees complete images.</p>
<a class="header" href="#fences" id="fences"><h3>Fences?</h3></a>
<p>A <a href="https://en.wikipedia.org/wiki/Memory_barrier">fence</a> (aka
<a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/VkFence.html">VkFence</a>)
is one of the two synchronization primitives we'll be dealing with. It's
basically just a bool, it can &quot;signaled&quot; or &quot;unsignaled&quot;. You can share a fence
between threads and everyone always sees the current state, so it's <em>like</em>
having an
<a href="https://doc.rust-lang.org/core/sync/atomic/struct.AtomicBool.html">AtomicBool</a>.</p>
<p>Fences are for CPU to GPU synchronization. The CPU can wait on a fence, and the
GPU will signal the fence when it's done whatever it's supposed to have done.</p>
<a class="header" href="#semaphores" id="semaphores"><h3>Semaphores?</h3></a>
<p>A <a href="https://en.wikipedia.org/wiki/Semaphore_(programming)">semaphore</a> (aka
<a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/VkSemaphore.html">VkSemaphore</a>)
is the other synchronization primitive that we deal with. In some contexts (eg:
<code>winapi</code>) a semaphore can be any integer value, but in a Vulkan / <code>gfx-hal</code>
context they can only be &quot;signaled&quot; or &quot;unsignaled&quot;.</p>
<p>The big difference between a fence and a semaphore is that semaphores are for
GPU to GPU synchronization. When once part of a graphics pipeline (such as
presentation to the swapchain) depends on another part of the pipeline (such as
command buffer processing), then you describe that dependency to the GPU using a
semaphore.</p>
<a class="header" href="#submission" id="submission"><h2>Submission</h2></a>
<p>Supposing that we already have a <code>CommandQueue</code> from somewhere, we need to give
it a <code>Submission</code> of what to do.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct Submission&lt;Ic, Iw, Is&gt; {
    pub command_buffers: Ic,
    pub wait_semaphores: Iw,
    pub signal_semaphores: Is,
}
#}</code></pre></pre>
<p>Hmm, but the <code>submit</code> method had extra bounds in there:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  T: 'a + Submittable&lt;B, C, Primary&gt;,
  Ic: IntoIterator&lt;Item = &amp;'a T&gt;,
  S: 'a + Borrow&lt;B::Semaphore&gt;,
  Iw: IntoIterator&lt;Item = (&amp;'a S, PipelineStage)&gt;,
  Is: IntoIterator&lt;Item = &amp;'a S&gt;,
#}</code></pre></pre>
<p>So if we put that together, and allow ourselves to use some slightly fake Rust
syntax for just a moment, we need to build this:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct Submission {
    pub command_buffers: IntoIterator&lt;Item = &amp;'a Submittable&lt;B, C, Primary&gt;&gt;,
    pub wait_semaphores: IntoIterator&lt;Item = (&amp;'a Borrow&lt;B::Semaphore&gt;, PipelineStage)&gt;,
    pub signal_semaphores: IntoIterator&lt;Item = &amp;'a Borrow&lt;B::Semaphore&gt;&gt;,
}
#}</code></pre></pre>
<ul>
<li><code>command_buffers</code> is our
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/command/trait.Submittable.html">Submittable</a>
things, which are <code>Borrow&lt;B::CommandBuffer&gt;</code>, so we can think of that as being
<em>sorta</em> like <code>&amp;[CommandBuffer]</code>.</li>
<li><code>wait_semaphores</code> gives the semaphores that this submission has to <em>wait on
before it starts</em>. Each semaphore is paired with a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.PipelineStage.html">PipelineStage</a>,
allowing your submission to wait for a stage, do some work at that stage, wait
for another stage, do some more work at the new stage, and so on.</li>
<li><code>signal_semaphores</code> gives a list of semaphores that this submission <em>will
signal once it completes</em>. It doesn't say, but I'm guessing that all the
semaphores just get signaled at once at the end of the Submission.</li>
</ul>
<p>All of this is basically what you find in the
<a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/VkSubmitInfo.html">VkSubmitInfo</a>
struct.</p>
<a class="header" href="#arrayvec-submissions" id="arrayvec-submissions"><h3>ArrayVec Submissions</h3></a>
<p>Remember when I said that we'd use the ArrayVec to avoid allocations per frame?
That's this part. It's simple really. Instead of writing something like:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let command_buffers = vec![the_command_buffer];
#}</code></pre></pre>
<p>You write something like</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let command_buffers: ArrayVec&lt;[_; 1]&gt; = [the_command_buffer].into();
#}</code></pre></pre>
<a class="header" href="#submitting-and-presenting" id="submitting-and-presenting"><h2>Submitting And Presenting</h2></a>
<p>So far it sounds like we want something like this</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub fn draw_clear_frame(&amp;mut self, color: [f32; 4]) -&gt; Result&lt;(), &amp;str&gt; {
    // SETUP FOR THIS FRAME
    // ...

    // RECORD SOME COMMANDS
    // ...

    // SUBMISSION
    let command_buffers: ArrayVec&lt;[_; 1]&gt; = [the_command_buffer].into();
    let wait_semaphores: ArrayVec&lt;[_; 1]&gt; = [(image_available, PipelineStage::COLOR_ATTACHMENT_OUTPUT)].into();
    let signal_semaphores: ArrayVec&lt;[_; 1]&gt; = [render_finished].into();
    let present_wait_semaphores: ArrayVec&lt;[_; 1]&gt; = [render_finished].into();
    let submission = Submission {
      command_buffers,
      wait_semaphores,
      signal_semaphores,
    };
    unsafe {
      the_command_queue.submit(submission, Some(flight_fence));
      the_swapchain.present(&amp;mut the_command_queue, i_u32, present_wait_semaphores)
        .map_err(|_|&quot;Failed to present into the swapchain!&quot;)
    }
  }
#}</code></pre></pre>
<p>For all my fuss about things being so &quot;manual and on your own&quot;, that seems
fairly reasonable so far.</p>
<a class="header" href="#recording-commands" id="recording-commands"><h2>Recording Commands</h2></a>
<p>So we need to fill up a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/command/struct.CommandBuffer.html">CommandBuffer</a>
with the operations that we want to have happen during the draw process.</p>
<p>All we want to do is clear the screen, that's got to be easy enough.</p>
<p>Well, it turns out that a CommandBuffer isn't totally free to make, so we want
to make them ahead of time and then pick out and use a particular command buffer
each frame. That's easy, we can change our Submission declaration very easily.
Also, before it's part of the Submission, we want to grab a <code>&amp;mut</code> to the
particular command buffer and write to it. That calls for the ever-lovable
&quot;inner scope&quot; so that the <code>&amp;mut</code> goes away and we can take a <code>&amp;</code> to our buffer
instead. Thankfully (I guess), recording to a CommandBuffer is all unsafe, so
we can kill two birds with one stone.</p>
<p>A CommandBuffer is actually wrapping around a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/command/trait.RawCommandBuffer.html">RawCommandBuffer</a>
with some metadata for bonus type safety. All the real documentation is given on
the RawCommandBuffer type. Unfortunately, the methods aren't <em>exactly</em> the same
name. Hopefully that's fixed in 0.2.</p>
<p>We start by calling <code>begin</code></p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub unsafe fn begin(&amp;mut self, allow_pending_resubmit: bool)
#}</code></pre></pre>
<p>To begin the buffer overall. Then we start a particular render pass with</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub unsafe fn begin_render_pass_inline&lt;T&gt;(
    &amp;mut self, 
    render_pass: &amp;B::RenderPass, 
    frame_buffer: &amp;B::Framebuffer, 
    render_area: Rect, 
    clear_values: T
) -&gt; RenderPassInlineEncoder&lt;B&gt;
where
    T: IntoIterator,
    T::Item: Borrow&lt;ClearValue&gt;, 
#}</code></pre></pre>
<p>Which records a render pass with no secondary command buffers.</p>
<p>Next we... immediately finish the render pass. The RenderPass struct will define
how to deal with the color buffer, including the clear effect, and the
ClearValue just picks what color to clear to. We're already done.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub fn draw_clear_frame(&amp;mut self, color: [f32; 4]) -&gt; Result&lt;(), &amp;str&gt; {
    // SETUP FOR THIS FRAME
    // ...

    // RECORD SOME COMMANDS
    {
      let buffer = &amp;mut self.command_buffers[i_usize];
      let clear_values = [ClearValue::Color(ClearColor::Float(color))];
      buffer.begin(false);
      buffer.begin_render_pass_inline(
        &amp;self.render_pass,
        &amp;self.swapchain_framebuffers[i_usize],
        self.render_area,
        clear_values.iter(),
      );
      buffer.finish();
    }

    // SUBMISSION
    // ...
  }
#}</code></pre></pre>
<a class="header" href="#frame-setup" id="frame-setup"><h2>Frame Setup</h2></a>
<p>What's left to do as setup? Well, the GPU can be doing more than one of these
buffer things at once. When you've got several images all going on it's called
having frames &quot;in flight&quot;. At the start of each frame of work, we have to pick
the right fences and semaphores and all that for the current frame that we're
going to be working with. The simplest way is to just keep them in parallel
vectors and go through them like a ring buffer.</p>
<p>However, even once we've picked our current sync primitives, we have to
<a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/vkAcquireNextImageKHR.html">acquire</a>
a particular image to work with out of the swapchain. We don't move the whole
image out of the swapchain, we just get an index to target later with the
<code>present</code> method.</p>
<a class="header" href="#final-draw_clear_frame-code" id="final-draw_clear_frame-code"><h2>Final <code>draw_clear_frame</code> Code</h2></a>
<p>So now we put it all together, with the signaling in big caps to help make it
clear.</p>
<ul>
<li>Get our sync primitives out of our ring buffers</li>
<li>WAIT on the current <code>flight_fence</code> to know we're in the clear to use this
position of our ring buffer.</li>
<li>Reset that fence so we can pass it as part of our submission later.</li>
<li>Grab an image index that will SIGNAL the <code>image_available</code> semaphore once it's
fully ready.</li>
<li>Record our command buffer while we're waiting for that.</li>
<li>Submit a command buffer to WAIT on <code>image_available</code> and SIGNAL both
<code>render_finished</code> and <code>flight_fence</code>.</li>
<li>Present the results into the swapchain after a WAIT on <code>render_finished</code></li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  /// Draw a frame that's just cleared to the color specified.
  pub fn draw_clear_frame(&amp;mut self, color: [f32; 4]) -&gt; Result&lt;(), &amp;str&gt; {
    // SETUP FOR THIS FRAME
    let flight_fence = &amp;self.in_flight_fences[self.current_frame];
    let image_available = &amp;self.image_available_semaphores[self.current_frame];
    let render_finished = &amp;self.render_finished_semaphores[self.current_frame];
    // Advance the frame _before_ we start using the `?` operator
    self.current_frame = (self.current_frame + 1) % self.frames_in_flight;

    let (i_u32, i_usize) = unsafe {
      self
        .device
        .wait_for_fence(flight_fence, core::u64::MAX)
        .map_err(|_| &quot;Failed to wait on the fence!&quot;)?;
      self
        .device
        .reset_fence(flight_fence)
        .map_err(|_| &quot;Couldn't reset the fence!&quot;)?;
      let image_index = self
        .swapchain
        .acquire_image(core::u64::MAX, FrameSync::Semaphore(image_available))
        .map_err(|_| &quot;Couldn't acquire an image from the swapchain!&quot;)?;
      (image_index, image_index as usize)
    };

    // RECORD COMMANDS
    unsafe {
      let buffer = &amp;mut self.command_buffers[i_usize];
      let clear_values = [ClearValue::Color(ClearColor::Float(color))];
      buffer.begin(false);
      buffer.begin_render_pass_inline(
        &amp;self.render_pass,
        &amp;self.framebuffers[i_usize],
        self.render_area,
        clear_values.iter(),
      );
      buffer.finish();
    }

    // SUBMISSION AND PRESENT
    let command_buffers = &amp;self.command_buffers[i_usize..=i_usize];
    let wait_semaphores: ArrayVec&lt;[_; 1]&gt; = [(image_available, PipelineStage::COLOR_ATTACHMENT_OUTPUT)].into();
    let signal_semaphores: ArrayVec&lt;[_; 1]&gt; = [render_finished].into();
    // yes, you have to write it twice like this. yes, it's silly.
    let present_wait_semaphores: ArrayVec&lt;[_; 1]&gt; = [render_finished].into();
    let submission = Submission {
      command_buffers,
      wait_semaphores,
      signal_semaphores,
    };
    let the_command_queue = &amp;mut self.queue_group.queues[0];
    unsafe {
      the_command_queue.submit(submission, Some(flight_fence));
      self
        .swapchain
        .present(the_command_queue, i_u32, present_wait_semaphores)
        .map_err(|_| &quot;Failed to present into the swapchain!&quot;)
    }
  }
#}</code></pre></pre>
<a class="header" href="#initializing-halstate" id="initializing-halstate"><h1>Initializing <code>HalState</code></h1></a>
<p>So for our <code>draw_clear_frame</code> method to work it expects that we have many things
on hand as part of <code>HalState</code>. Listing them in the order that they're used:</p>
<ul>
<li>fences (requires a Device + frames_in_flight)</li>
<li>semaphores (requires a Device + frames_in_flight)</li>
<li>current_frame (just starts at 0)</li>
<li>frames_in_flight (comes from the Swapchain)</li>
<li>device (requires an Adapter)</li>
<li>swapchain (requires a Surface+Adapter+Device)</li>
<li>command_buffers (requires a CommandPool)</li>
<li>render_pass (requires a Device)</li>
<li>swapchain_framebuffers (requires ImageView values)</li>
<li>render_area (comes from the Swapchain)</li>
<li>queue_group (requires an Adapter)</li>
</ul>
<p>But, as you can probably guess, that's <em>not</em> the order that they're initialized.
You should have noticed that there's some things on there we haven't even
discussed yet, which also have their requirements. In no particular order:</p>
<ul>
<li>image_views (requires a Device+Backbuffer)</li>
<li>backbuffer (requires Surface+Adapter)</li>
<li>Command Pool (requires Device)</li>
<li>Surface (requires an Instance+Window)</li>
<li>Adapter (requires an Instance)</li>
<li>Instance</li>
</ul>
<p>Now we just re-order it all so that nothing is built before the parts it depends
on. We'll even add some names to the build phases to help group it mentally:</p>
<ul>
<li>Top Level Stuff
<ul>
<li>Instance</li>
<li>Surface (requires an Instance+Window)</li>
<li>Adapter (requires an Instance)</li>
<li>queue_group (requires an Adapter)</li>
<li>device (requires an Adapter)</li>
</ul>
</li>
<li>The GPU Swapchain
<ul>
<li>swapchain (requires a Surface+Adapter+Device)</li>
<li>backbuffer (requires Surface+Adapter)</li>
<li>render_area (comes from the Swapchain)</li>
<li>frames_in_flight (comes from the Swapchain)</li>
<li>fences (requires a Device + frames_in_flight)</li>
<li>semaphores (requires a Device + frames_in_flight)</li>
</ul>
</li>
<li>RenderPass
<ul>
<li>render_pass (requires a Device + Swapchain format)</li>
</ul>
</li>
<li>Targets For Rendering
<ul>
<li>image_views (requires a Device+Backbuffer)</li>
<li>framebuffers (requires ImageView values)</li>
</ul>
</li>
<li>Command Issuing
<ul>
<li>Command Pool (requires Device)</li>
<li>command_buffers (requires a CommandPool + Swapchain)</li>
</ul>
</li>
<li>Misc
<ul>
<li>current_frame (just starts at 0)</li>
</ul>
</li>
</ul>
<p>Notice that after the initial top level stuff you can do the other general
phases in about any order you want. You use the parts that they each build all
at once during rendering, but they can be constructed and configured
independently.</p>
<p>Also, there's many other things that a person might initialize in <code>gfx-hal</code>.
That's why we looked at how to submit the command we wanted first, so we don't
go wandering off initializing all sorts of things we don't end up needing.</p>
<p>And I guess we can just copy this outline as our outline for the explanation of
each step too. Nice when things work out like that.</p>
<a class="header" href="#top-level-stuff" id="top-level-stuff"><h2>Top Level Stuff</h2></a>
<p>Alright, so we're going to initialize a <code>HalState</code>. Well, just as with drawing,
there might be any number of problems that come up during this many step
process.</p>
<p>So the method we're filling in looks like this:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl HalState {
  pub fn new(window: &amp;Window) -&gt; Result&lt;Self, &amp;'static str&gt; {
    unimplemented!()
  }
}
#}</code></pre></pre>
<a class="header" href="#instance" id="instance"><h3>Instance</h3></a>
<p>An <code>Instance</code> is a backend specific black box. It's the handle that you hold to
prove that you've activated the backend API, and when it drops the backend tries
to close down, so you have to hold on to it at the very end and let it go last.</p>
<p>For something so important, you'd imagine that there's a dedicated trait for
them, and <a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/trait.Instance.html">you'd be
right</a>. You'd also
expect that the trait includes a way to create them instead of leaving it up to
convention, and you'd be wrong.</p>
<p>Still, it's very easy. We give an instance name and a version and the details of
how that's used depend on the backend.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let instance = back::Instance::create(WINDOW_NAME, 1);
#}</code></pre></pre>
<a class="header" href="#surface" id="surface"><h3>Surface</h3></a>
<p>The <a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/trait.Surface.html">Surface</a>
is an abstraction of how the <code>Window</code> (from <code>winit</code>) and your <code>Instance</code> (from
your <code>gfx-backend-whatever</code>) will actually be able to interact and show
something on the screen.</p>
<p>Similar to the Instance, it's very important, but also totally boring to create:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let mut surface = instance.create_surface(window);
#}</code></pre></pre>
<p>As far as I can tell, it has no special cleanup operation. It probably shouldn't
outlive the Instance or the Window, but that's just a best guess.</p>
<a class="header" href="#adapter" id="adapter"><h3>Adapter</h3></a>
<p>The <a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/adapter/struct.Adapter.html">Adapter</a>
is... <em>something</em> that supports the usage of the API you've got an Instance for.
It's <em>probably</em> a hardware GPU, but it could technically be a purely software
implementation.</p>
<p>We actually don't <em>make</em> an Adapter, we pick one that already exists. Once we've
picked one, we haven't even made any changes to the system. Picking an Adapter
is like picking a IP address to connect to. It's one step to select the IP
address you want, and then another step to actually open a connection to that IP
address (which we'll do in a moment).</p>
<p>We have to call
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/trait.Instance.html#tymethod.enumerate_adapters">Instance::enumerate_adapters</a>,
which gives a vector of things to pick from. Our criteria here is based on the <code>queue_families: Vec&lt;B::QueueFamily&gt;</code> that each Adapter has. We want a QueueFamily</p>
<ol>
<li>That supports Graphics</li>
<li>That our Surface supports</li>
</ol>
<p>It's considered a bug in <code>gfx-hal</code> if any backend ever gives a QueueFamily that
has 0 max queues, so we don't need to bother checking that.</p>
<p>Since we're going over a vector, we can use some fancy Iterator stuff</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let adapter = instance
  .enumerate_adapters()
  .into_iter()
  .find(|a| {
    a.queue_families
      .iter()
      .any(|qf| qf.supports_graphics() &amp;&amp; surface.supports_queue_family(qf))
  })
  .ok_or(&quot;Couldn't find a graphical Adapter!&quot;)?;
#}</code></pre></pre>
<a class="header" href="#device-and-queuegroup" id="device-and-queuegroup"><h3>Device and QueueGroup</h3></a>
<p>This is a &quot;two things in one step&quot; situation. From here on out we'll be doing a
lot of steps where we have an inner scope do to some setup, then we pass the
important data back up to the <code>new</code> method's primary scope. It's a Rust take on
what you might call &quot;<a href="http://number-none.com/blow/blog/programming/2014/09/26/carmack-on-inlined-code.html">Style
C</a>&quot;
coding. We're just going to let the method get super long, with every single
step being as plan and obvious as possible, to see the full horror of what we're
doing.</p>
<p>The actual process here is easy enough to understand.</p>
<ul>
<li>Every Adapter has a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/adapter/trait.PhysicalDevice.html">PhysicalDevice</a>,
and you call <code>open</code> to actually &quot;connect&quot; your program to that PhysicalDevice.
This (hopefully) gives a Gpu. You have to pass in a list of QueueFamily values
with a priority for each one.</li>
<li>A <a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/struct.Gpu.html">Gpu</a> is a pairing of
a <a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/device/trait.Device.html">Device</a>
(which is a logical device, but you use it so often they wanted to make the
name shorter) and a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/queue/family/struct.Queues.html">Queues</a>
value, which is a container for the different queues that we can now use.</li>
<li>Once we've got the Queues, we pull out a particular
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/queue/family/struct.QueueGroup.html">QueueGroup</a>
as well, which we use much later to build the CommandPool, and also it's how
we <code>submit</code> our written CommandBuffer values of course.</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let (device, queue_group) = {
  let queue_family = adapter
    .queue_families
    .iter()
    .find(|qf| qf.supports_graphics() &amp;&amp; surface.supports_queue_family(qf))
    .ok_or(&quot;Couldn't find a QueueFamily with graphics!&quot;)?;
  let Gpu { device, mut queues } = unsafe {
    adapter
      .physical_device
      .open(&amp;[(&amp;queue_family, &amp;[1.0; 1])])
      .map_err(|_| &quot;Couldn't open the PhysicalDevice!&quot;)?
  };
  let queue_group = queues
    .take::&lt;Graphics&gt;(queue_family.id())
    .ok_or(&quot;Couldn't take ownership of the QueueGroup!&quot;)?;
  let _ = if queue_group.queues.len() &gt; 0 {
    Ok(())
  } else {
    Err(&quot;The QueueGroup did not have any CommandQueues available!&quot;)
  }?;
  (device, queue_group)
};
#}</code></pre></pre>
<p>Now, I can already <em>hear</em> you trying to tell me that we shouldn't repeat the
<code>find</code> operation, but because of how the lifetimes work out we can't hang on to
a <code>queue_family</code> and also use our Adapter normally because the QueueFamily
reference keeps the Adapter borrowed the whole time, and it's a mess. <strong>Even
if</strong> we didn't care about lifetime issues the two <code>find</code> operations are actually
different because one works on <code>&amp;</code> and the other is working on <code>&amp;&amp;</code> and we just
don't happen to <em>see</em> the difference because of <a href="https://doc.rust-lang.org/book/ch15-02-deref.html?highlight=deref#implicit-deref-coercions-with-functions-and-methods">Deref
coercion</a>.
It's fine to just do it twice, don't worry too much about it, really.</p>
<a class="header" href="#the-gpu-swapchain" id="the-gpu-swapchain"><h2>The GPU Swapchain</h2></a>
<p>The
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/trait.Swapchain.html">Swapchain</a>
is like a collection of images on the GPU. They've got a linear index, like an
array or vector, and the GPU jumps around the Swapchain showing one image at any
given moment. This is where things start to get more configurable.</p>
<a class="header" href="#swapchain-and-friends" id="swapchain-and-friends"><h3>Swapchain and friends</h3></a>
<p>The basic idea is that you call
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/trait.Surface.html#tymethod.compatibility">Surface::compatibility</a>
to get information about what sort of
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/struct.SwapchainConfig.html">SwapchainConfig</a>
you're allowed to build, and then you call
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/device/trait.Device.html#tymethod.create_swapchain">Device::create_swapchain</a>
with your Surface and the config you want. This gives you a Swapchain, which has
methods for controlling the GPU's swapchain, as well as a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/enum.Backbuffer.html">Backbuffer</a>,
which holds the handles to particular Image data. We use an Image to make an
ImageView, and we use that to make a Framebuffer, and <em>that's</em> what we're
manipulating with the CommandBuffer.</p>
<p>So what SwapchainConfig do we try to build? Well, the best one we can.
Unfortunately, this varies by quite a bit. Even if I just switch from the Vulkan
backend to the DX12 backend on a single machine the system ends up giving me
different compatibility results.</p>
<p>The SwapchainConfig type does have a <code>from_caps</code> method to try and help you
build a value, but it's shockingly error prone, because not all of the
capabilities of your Surface are actually contained in the SurfaceCapabilities
struct! The <code>Surface::compatibility</code> also gives you Format, PresentMode, and
CompositeAlpha that you have to pay attention to, which <code>from_caps</code> totally
ignores. We're not going to use that, we'll just write out a struct literal
ourselves. SwapchainConfig looks like this:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct SwapchainConfig {
  pub present_mode: PresentMode,
  pub composite_alpha: CompositeAlpha,
  pub format: Format,
  pub extent: Extent2D,
  pub image_count: SwapImageIndex,
  pub image_layers: Layer,
  pub image_usage: Usage,
}
#}</code></pre></pre>
<ul>
<li><code>present_mode</code>:
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/enum.PresentMode.html">PresentMode</a>
gives us access to that sweet, sweet Vsync. Well, if it's available.
<ul>
<li>We would most like to have <code>Mailbox</code>, which lets us do &quot;triple buffering&quot;.
That's where you have at least 3 images, and one is &quot;being shown&quot; and then
you render frames as quick as you can to different swapchain slots, always
keeping the most recent complete frame ready. This gives the least amount of
latency between user input and what they see on the screen.</li>
<li>We would accept <code>Fifo</code>, where frames are shown in the exact order that they're
created. If you do this with 2 images you can have &quot;double buffering&quot; (where
you show one frame and work on the next), but if you're using this with more
than two images then it causes excess latency between input and display.</li>
<li>We would begrudgingly accept <code>Relaxed</code> if we had to use it, which &quot;usually&quot;
has vsync but not always. I suppose this is for low-end machines. We want to
avoid this if we can.</li>
<li>We would hate to have to use <code>Immediate</code>, where there's no vsync at all.
That would just be terrible. We could live with it, but it'd be terrible
because we'd have to sync the program ourselves to avoid eating up 100% of
the core (and all of the user's battery, if they're on a mobile device).</li>
</ul>
</li>
<li><code>composite_alpha</code>:
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/enum.CompositeAlpha.html">CompositeAlpha</a>
controls how your window interacts with other windows within the user's UI.
<ul>
<li>For now we'd prefer <code>Opaque</code>, so that we just show our window &quot;normally&quot;.</li>
<li>We'd also accept <code>Native</code>, because we trust the user to have set things up
how they want.</li>
<li><code>PreMultiplied</code> or <code>PostMultiplied</code> will almost certainly give &quot;wrong&quot;
results because our graphics aren't smart enough to compensate for being
forced into such a mode. Well, they'd be wrong if our graphics were anything
more than a single clear color, but you know what I mean.</li>
</ul>
</li>
<li><code>format</code>: The
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/format/enum.Format.html">Format</a> of the
swapchain is how the data for each pixel is expected to exist in memory.
<em>Normally</em> we'd be a lot more interested, but since we're just clearing the
screen it doesn't super matter. Still, we'll try to pick an sRGB format (which
stands for &quot;standard Red Green Blue&quot;), just because that's what we'll be using
in basically all the future lessons. Here we've got an <code>Option&lt;Vec&lt;_&gt;&gt;</code>, which
means that the selection block will be silly and fiddly.</li>
<li><code>extent</code>: The
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/struct.Extent2D.html">Extent2D</a>
describes a full sized rectangle (not a sub-rectangle), and selects a size for
our images. Here's where we start using the SurfaceCapabilities that we got
earlier. The SwapchainConfig <code>extent</code> that we use must be within the range
that the <code>extents: Range&lt;Extent2D&gt;</code> field in our SurfaceCapabilities
specifies. Note that the
<a href="https://doc.rust-lang.org/nightly/core/ops/struct.Range.html">Range</a> type is
semantically supposed to be <em>exclusive</em> but both the Vulkan and DX12 backends
use it wrong, so it's actually an inclusive value here.
<ul>
<li>As far as what extent we're actually going to pick, we'll go as big as we
can. The Surface should should end up being the size of our Window, so our
images are just &quot;normal&quot; size and it all works out.</li>
</ul>
</li>
<li><code>image_count</code>: The
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/window/type.SwapImageIndex.html">SwapImageIndex</a>
is just a <code>u32</code> for how many images we want in our Swapchain. Like I said, if
we're going to be using <code>Mailbox</code> then we want 3, otherwise we'll go with 2.
Note that we have to respect the <code>image_count: Range&lt;SwapImageIndex&gt;</code> field of
the SurfaceCapabilities, which is <em>another</em> field that is a Range but should
actually be a RangeInclusive.</li>
<li><code>image_layers</code>: The
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/image/type.Layer.html">Layer</a> is just a
<code>u16</code> for how many layers we want in our image. 1 is fine.</li>
<li><code>image_usage</code>: The
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/image/struct.Usage.html">Usage</a> defines
how we'll be using the images in the swap chain in terms of the render pass
stuff. We'll be using just color for now, so we check for that.</li>
</ul>
<p>With that all done, we make the SwapchainConfig and then we use the Device to
build a Swapchain and Backbuffer pair. This is a very vertical portion of code,
but not too much is actually happening.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let (swapchain, extent, backbuffer, format, frames_in_flight) = {
  let (caps, preferred_formats, present_modes, composite_alphas) = surface.compatibility(&amp;adapter.physical_device);
  info!(&quot;{:?}&quot;, caps);
  info!(&quot;Preferred Formats: {:?}&quot;, preferred_formats);
  info!(&quot;Present Modes: {:?}&quot;, present_modes);
  info!(&quot;Composite Alphas: {:?}&quot;, composite_alphas);
  //
  let present_mode = {
    use gfx_hal::window::PresentMode::*;
    [Mailbox, Fifo, Relaxed, Immediate]
      .iter()
      .cloned()
      .find(|pm| present_modes.contains(pm))
      .ok_or(&quot;No PresentMode values specified!&quot;)?
  };
  let composite_alpha = {
    use gfx_hal::window::CompositeAlpha::*;
    [Opaque, Inherit, PreMultiplied, PostMultiplied]
      .iter()
      .cloned()
      .find(|ca| composite_alphas.contains(ca))
      .ok_or(&quot;No CompositeAlpha values specified!&quot;)?
  };
  let format = match preferred_formats {
    None =&gt; Format::Rgba8Srgb,
    Some(formats) =&gt; match formats
      .iter()
      .find(|format| format.base_format().1 == ChannelType::Srgb)
      .cloned()
    {
      Some(srgb_format) =&gt; srgb_format,
      None =&gt; formats.get(0).cloned().ok_or(&quot;Preferred format list was empty!&quot;)?,
    },
  };
  let extent = caps.extents.end;
  let image_count = if present_mode == PresentMode::Mailbox {
    (caps.image_count.end - 1).min(3)
  } else {
    (caps.image_count.end - 1).min(2)
  };
  let image_layers = 1;
  let image_usage = if caps.usage.contains(Usage::COLOR_ATTACHMENT) {
    Usage::COLOR_ATTACHMENT
  } else {
    Err(&quot;The Surface isn't capable of supporting color!&quot;)?
  };
  let swapchain_config = SwapchainConfig {
    present_mode,
    composite_alpha,
    format,
    extent,
    image_count,
    image_layers,
    image_usage,
  };
  info!(&quot;{:?}&quot;, swapchain_config);
  //
  let (swapchain, backbuffer) = unsafe {
    device
      .create_swapchain(&amp;mut surface, swapchain_config, None)
      .map_err(|_| &quot;Failed to create the swapchain!&quot;)?
  };
  (swapchain, extent, backbuffer, format, image_count as usize)
};
#}</code></pre></pre>
<a class="header" href="#render_area" id="render_area"><h4>render_area</h4></a>
<p>This is a <a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.Rect.html">Rect</a>
version of our Extent2D. While an Extent2D is semantically the full area of an
image or texture (storing only width:<code>u32</code> and height:<code>u32</code>), a Rect is some
sub-portion of such an area (storing x,y,w,h, all <code>i16</code>). Note that your
sub-portion can totally just be &quot;all of it&quot;.</p>
<a class="header" href="#frames_in_flight" id="frames_in_flight"><h4>frames_in_flight</h4></a>
<p>This is just us storing how many images are in our Swapchain. As you saw when we
cleared the screen, we'll have one set of just about everything per frame in
flight.</p>
<a class="header" href="#fences-and-semaphores" id="fences-and-semaphores"><h3>Fences and Semaphores</h3></a>
<p>Generating the Fence and Semaphore values is quite boring. You just call
<code>create_fence</code> and <code>create_semaphore</code> on your Device value, over and over until
you have enough. Technically this might cause an OutOfMemory problem on the GPU,
but that's not very likely, so there's little chance that we'll have a problem
in this stage of things.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let (image_available_semaphores, render_finished_semaphores, in_flight_fences) = {
  let mut image_available_semaphores: Vec&lt;&lt;back::Backend as Backend&gt;::Semaphore&gt; = vec![];
  let mut render_finished_semaphores: Vec&lt;&lt;back::Backend as Backend&gt;::Semaphore&gt; = vec![];
  let mut in_flight_fences: Vec&lt;&lt;back::Backend as Backend&gt;::Fence&gt; = vec![];
  for _ in 0..frames_in_flight {
    in_flight_fences.push(device.create_fence(true).map_err(|_| &quot;Could not create a fence!&quot;)?);
    image_available_semaphores.push(device.create_semaphore().map_err(|_| &quot;Could not create a semaphore!&quot;)?);
    render_finished_semaphores.push(device.create_semaphore().map_err(|_| &quot;Could not create a semaphore!&quot;)?);
  }
  (image_available_semaphores, render_finished_semaphores, in_flight_fences)
};
#}</code></pre></pre>
<a class="header" href="#renderpass" id="renderpass"><h2>RenderPass</h2></a>
<p>A RenderPass describes each part of the whole graphical processing for an image.
Well, actually it describes one &quot;pass&quot; which has various &quot;sub-passes&quot;, but you
can also do multi-pass rendering, and then each pass can have its own
sub-passes. It's a lot of organization you might need to keep track of, but it
lets you be very precise about what happens when.</p>
<p>The RenderPass type has a backend specific definition so there's no general
struct here, not even a trait for them, unfortunately. Instead, you make one
with
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/device/trait.Device.html#tymethod.create_render_pass">Device::create_render_pass</a>.
This works a lot like that Submission stuff we had to deal with before, where
we'll have lists of stuff that all kinda get piled together. We need one
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pass/struct.Attachment.html">Attachment</a>
value (for the color), one
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pass/struct.SubpassDesc.html">SubpassDesc</a>
value (remember how we did a single &quot;inline&quot; render pass?), and then naturally
we have no
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pass/struct.SubpassDependency.html">SubpassDependency</a>
values since we only have a single subpass.</p>
<ul>
<li>Our Attachment needs
<ul>
<li><code>format</code>: the format that we picked out for our Swapchain to be using.</li>
<li><code>samples</code>: is only used when you get to multisampling, which is a later lesson.</li>
<li><code>ops</code>: determines what to do with the data in this Attachment at the start
of the subpass and at the end of the subpass. Remember how we recorded a
command that set a clear color and nothing else? That didn't even do the
clearing. <em>This</em> is the part that does the clearing. When the subpass begins
the old color value is all cleared. When the subpass ends the color values
are stored.</li>
<li><code>stencil_ops</code>: Is something we'll use later, but for now <code>DONT_CARE</code> is
sufficient. I guess this is one of the few places where we kinda have a
default to work with.</li>
<li><code>layouts</code>: This lets us define the starting and ending pixel layout of the
image we're processing. Each image has a pixel format which doesn't change
from pass to pass, but it also has a layout that does change from pass to
pass. It depends on what the image is being used for. In our case it starts
as Undefined (since nothing happened before this) and it ends with Present
(since we're done and want to present the image). Once again, we're using a
Range when the type <em>should be</em> RangeInclusive, or even maybe just a tuple.</li>
</ul>
</li>
<li>Our SubpassDesc needs the color attachment, and no others. This is where you
<em>can</em> get really fancy with &quot;post-processing effects&quot; type of stuff. We just
need one
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pass/type.AttachmentRef.html">AttachmentRef</a>
for our colors. An ID value (0 is fine) and a layout. <em>During</em> this pass we'll
be affecting the color, so we'll pick <code>ColorAttachmentOptimal</code>. Well, we don't
affect the colors after the clear during this tutorial, but once we start
drawing stuff it'll matter, so we might as well set it now.</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let render_pass = {
  let color_attachment = Attachment {
    format: Some(format),
    samples: 1,
    ops: AttachmentOps {
      load: AttachmentLoadOp::Clear,
      store: AttachmentStoreOp::Store,
    },
    stencil_ops: AttachmentOps::DONT_CARE,
    layouts: Layout::Undefined..Layout::Present,
  };
  let subpass = SubpassDesc {
    colors: &amp;[(0, Layout::ColorAttachmentOptimal)],
    depth_stencil: None,
    inputs: &amp;[],
    resolves: &amp;[],
    preserves: &amp;[],
  };
  unsafe {
    device
      .create_render_pass(&amp;[color_attachment], &amp;[subpass], &amp;[])
      .map_err(|_| &quot;Couldn't create a render pass!&quot;)?
  }
};
#}</code></pre></pre>
<a class="header" href="#targets-for-rendering" id="targets-for-rendering"><h2>Targets For Rendering</h2></a>
<p>We've got all these images, but we can't use them as it is. Vulkan wants to know
more because it wants all the memory for each step to be as perfectly laid out
as possible.</p>
<a class="header" href="#imageview" id="imageview"><h3>ImageView</h3></a>
<p>First we have to take the Images (in the Backbuffer) and then make one ImageView
each. This adds the metadata to each image on how we're using it.</p>
<p>There's not too much to say about the process here. The Backbuffer technically
can hold two possible setups, one of which is for OpenGL and the other of which
is for everything else. It throws a bit of a wrench into our plans to support
the OpenGL setup so... well we just won't do it for now. After that's settled
it's just a simple map operation where we call
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/device/trait.Device.html#tymethod.create_image_view">Device::create_image_view</a>
a bunch and collect it all up.</p>
<p>We've seen some of this before.</p>
<ul>
<li><a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/image/enum.ViewKind.html">ViewKind</a>
lets us pick that we want this ImageView to be a 2D image, which is already
enough of a heads up to know that an &quot;Image&quot; can get pretty weird the farther
we go into this and the more types of ViewKind we eventually use.</li>
<li><a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/format/struct.Swizzle.html">Swizzle</a>
gives you the ability to transition between two different color channel
orderings, but we have no need for that now so we can use the <code>NO</code> constant.</li>
<li><a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/image/struct.SubresourceRange.html">SubresourceRange</a>
lets us pick what sub-resources (eg: Color / Depth / Stencil) are used at what
mipmap levels (think &quot;zoom levels&quot;), and in what parts of the array (if our
image is an array, which it's not).</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let image_views: Vec&lt;_&gt; = match backbuffer {
  Backbuffer::Images(images) =&gt; images
    .into_iter()
    .map(|image| unsafe {
      device
        .create_image_view(
          &amp;image,
          ViewKind::D2,
          format,
          Swizzle::NO,
          SubresourceRange {
            aspects: Aspects::COLOR,
            levels: 0..1,
            layers: 0..1,
          },
        )
        .map_err(|_| &quot;Couldn't create the image_view for the image!&quot;)
    })
    .collect::&lt;Result&lt;Vec&lt;_&gt;, &amp;str&gt;&gt;()?,
  Backbuffer::Framebuffer(_) =&gt; unimplemented!(&quot;Can't handle framebuffer backbuffer!&quot;),
};
#}</code></pre></pre>
<a class="header" href="#framebuffer" id="framebuffer"><h3>Framebuffer</h3></a>
<p>Once we've got our ImageView values set, we can get one Framebuffer for each
with
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/device/trait.Device.html#tymethod.create_framebuffer">Device::create_framebuffer</a>.
This is what we actually target with our CommandBuffer recordings. It's another
quick map operation, even less to say than with the ImageViews.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let framebuffers: Vec&lt;&lt;back::Backend as Backend&gt;::Framebuffer&gt; = {
  image_views
    .iter()
    .map(|image_view| unsafe {
      device
        .create_framebuffer(
          &amp;render_pass,
          vec![image_view],
          Extent {
            width: extent.width as u32,
            height: extent.height as u32,
            depth: 1,
          },
        )
        .map_err(|_| &quot;Failed to create a framebuffer!&quot;)
    })
    .collect::&lt;Result&lt;Vec&lt;_&gt;, &amp;str&gt;&gt;()?
};
#}</code></pre></pre>
<p>There's a use of <code>vec!</code> in there that we <em>could</em> avoid with the same ArrayVec
deal that we used before, but this is startup code so we don't quite need to
bother. We'll only have 2 or 3 framebuffers anyway, it's fine.</p>
<a class="header" href="#command-issuing" id="command-issuing"><h2>Command Issuing</h2></a>
<p>We're in the home stretch, we just need to initialize the ability to issue
commands so we can put all these other things into use.</p>
<p>It's so simple we won't even use sub-sections:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let mut command_pool = unsafe {
  device
    .create_command_pool_typed(&amp;queue_group, CommandPoolCreateFlags::RESET_INDIVIDUAL)
    .map_err(|_| &quot;Could not create the raw command pool!&quot;)?
};
#}</code></pre></pre>
<p>The <code>RESET_INDIVIDUAL</code> flag lets us reset individual command buffers that come
out of this pool (without the flag you have to reset the whole pool at once).</p>
<p>Once we have a CommandPool we make it give us one CommandBuffer for each
Framebuffer that we ended up with.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let command_buffers: Vec&lt;_&gt; = framebuffers.iter().map(|_| command_pool.acquire_command_buffer()).collect();
#}</code></pre></pre>
<a class="header" href="#current_frame" id="current_frame"><h3>current_frame</h3></a>
<p>I guess you could say that this is part of the command issuing maybe? I don't
know, but we've been initializing for a super long time and I'm getting sick of
it, so you probably are too. This value is just a <code>usize</code> tracking what set of
stuff to use, and it starts at 0.</p>
<a class="header" href="#cleaning-up-halstate" id="cleaning-up-halstate"><h1>Cleaning Up <code>HalState</code></h1></a>
<p>There's two situations where we'd need to clean up the <code>HalState</code> stuff:</p>
<ul>
<li>Drop triggering, for any reason: Easy to do, we'll show that in a moment, once
we've talked about this other situation we have to handle</li>
<li><code>new</code> returning before the <code>HalState</code> struct is actually declared (which means
that <code>HalState::drop</code> doesn't get called): Very un-ergonomic to handle
properly. Like, seriously it's bad. You could re-arrange all of the code so
that <em>every single</em> early return (the <code>?</code> parts) is actually resource safe,
but we're totally not even going to do that. It's just too terrible to try.
Every single potential early return would create a new indentation for the
main code and a custom cleanup block we'd have to write in the error case. I
don't even want to think about it.</li>
</ul>
<p>Why so? Well, almost none of the resource types are self-destructing, so even
though an early return causes them to die <a href="https://github.com/rust-lang/rfcs/blob/master/text/1857-stabilize-drop-order.md">in the proper
order</a>
(that is, we <em>always</em> want LIFO destruction), their moment of destruction
doesn't actually <em>do</em> anything because they don't have their own Drop code.
<em>This isn't anyone's fault</em>. I know in a few spots I've taken a few jabs at the
gfx team for using Range instead of RangeInclusive or something like that, but
this one they really can't fix.</p>
<p>Anything that comes from <code>Device::create_foo</code> needs to be destroyed by calling
<code>Device::destroy_foo</code> using that same device. So, either we need to have a
globally set Device value so that anyone's drop code can call <code>destroy_*</code> at any
time (rather bad to have such a global), or every single thing to later be
destroyed has to carry with it a copy of the Device so that they can use it to
destroy themselves (arguably worse in terms of overhead). It's just... it's just
not a good situation at all. We'll just have to be aware that our HalState
initialization code is just fundamentally broken for early returns, and it
probably always will be.</p>
<p>What are the <em>consequences</em> for any kind of improper resource destruction like
that? Well, it depends. Which is terrible to have to say, but it does. <em>Usually</em>
you get a resource leak but life goes on as long as everything that comes out of
your Instance goes away before your Instance does. If you try to destroy the
Instance before things that came out of it you'll (probably) segfault your
process on the Vulkan backend. DX12 doesn't seem to mind. I don't know about
Metal since I don't own a mac.</p>
<p>I feel about as bad for being so vague about it as you probably feel for having
to read it, but these are just the troubles with FFI.</p>
<a class="header" href="#waiting-until-idle" id="waiting-until-idle"><h3>Waiting Until Idle</h3></a>
<p>The first thing we do in the drop method is wait for the device to go idle. It's
not legal to destroy resources that are in use, so we just give it a moment to
cool down by calling
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/device/trait.Device.html#tymethod.wait_idle">Device::wait_idle</a>.
This could technically error, but at this point we're tearing it all down so we
don't care about the error. The device had its chance and now we're in charge.</p>
<a class="header" href="#basic-destruction" id="basic-destruction"><h3>Basic Destruction</h3></a>
<p>As I said, anything that comes from <code>Device::create_foo</code> needs to go back to a
<code>Device::destroy_foo</code> call. If those things are stored in vectors, it's easy to
drain out the vector and destroy them one at a time.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl core::ops::Drop for HalState {
  /// We have to clean up &quot;leaf&quot; elements before &quot;root&quot; elements. Basically, we
  /// clean up in reverse of the order that we created things.
  fn drop(&amp;mut self) {
    let _ = self.device.wait_idle();
    unsafe {
      for fence in self.in_flight_fences.drain(..) {
        self.device.destroy_fence(fence)
      }
#}</code></pre></pre>
<p>And so on, for all of the things that are stored in vectors.</p>
<a class="header" href="#manuallydrop" id="manuallydrop"><h3>ManuallyDrop</h3></a>
<p>What do we do about things that aren't stored in vectors? We need to pass them
to <code>destroy_foo</code> but that's by-value and we can't move them out of a borrowed
context (since we're using <code>&amp;mut self</code> within the <code>drop</code> call).</p>
<p>The answer is that we cheat.</p>
<p>If we just use
<a href="https://doc.rust-lang.org/core/ptr/fn.read.html">core::ptr::read</a> we can make a
duplicate of any bits we want. The type doesn't even have to be Clone! It's as
unsafe as it sounds. How do we offset some of that? With a marker struct called
<a href="https://doc.rust-lang.org/core/mem/struct.ManuallyDrop.html">ManuallyDrop</a>,
which is magically known to the compiler, and the thing inside of the
ManuallyDrop will never run its own destructor automatically. When it's really
time to destroy the thing we can call <code>ManuallyDrop::into_inner</code> to unwrap the
value and pass it to some destroy function, or we can call <code>ManuallyDrop::drop</code>
to force the drop to happen on something that we don't have ownership of. We're
actually going to use <em>both</em> styles.</p>
<p>For things that go with a <code>destroy_foo</code> method we'll use the <code>::into_inner</code>
style:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
// The CommandPool must also be unwrapped into a RawCommandPool,
// so there's an extra `into_raw` call here.
self
  .device
  .destroy_command_pool(ManuallyDrop::into_inner(read(&amp;mut self.command_pool)).into_raw());
self
  .device
  .destroy_render_pass(ManuallyDrop::into_inner(read(&amp;mut self.render_pass)));
self
  .device
  .destroy_swapchain(ManuallyDrop::into_inner(read(&amp;mut self.swapchain)));
#}</code></pre></pre>
<p>And for our two final items we just use the <code>ManuallyDrop::drop</code> style:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
ManuallyDrop::drop(&amp;mut self.device);
ManuallyDrop::drop(&amp;mut self._instance);
#}</code></pre></pre>
<a class="header" href="#final-halstate-definition" id="final-halstate-definition"><h1>Final <code>HalState</code> Definition</h1></a>
<p>Now that we know all of the fields that we have, including which ones are
wrapped in <code>ManuallyDrop</code>, we can look at our crazy, ugly, horrible <code>HalState</code>:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct HalState {
  current_frame: usize,
  frames_in_flight: usize,
  in_flight_fences: Vec&lt;&lt;back::Backend as Backend&gt;::Fence&gt;,
  render_finished_semaphores: Vec&lt;&lt;back::Backend as Backend&gt;::Semaphore&gt;,
  image_available_semaphores: Vec&lt;&lt;back::Backend as Backend&gt;::Semaphore&gt;,
  command_buffers: Vec&lt;CommandBuffer&lt;back::Backend, Graphics, MultiShot, Primary&gt;&gt;,
  command_pool: ManuallyDrop&lt;CommandPool&lt;back::Backend, Graphics&gt;&gt;,
  framebuffers: Vec&lt;&lt;back::Backend as Backend&gt;::Framebuffer&gt;,
  image_views: Vec&lt;(&lt;back::Backend as Backend&gt;::ImageView)&gt;,
  render_pass: ManuallyDrop&lt;&lt;back::Backend as Backend&gt;::RenderPass&gt;,
  render_area: Rect,
  queue_group: QueueGroup&lt;back::Backend, Graphics&gt;,
  swapchain: ManuallyDrop&lt;&lt;back::Backend as Backend&gt;::Swapchain&gt;,
  device: ManuallyDrop&lt;back::Device&gt;,
  _adapter: Adapter&lt;back::Backend&gt;,
  _surface: &lt;back::Backend as Backend&gt;::Surface,
  _instance: ManuallyDrop&lt;back::Instance&gt;,
}
#}</code></pre></pre>
<a class="header" href="#everything-else" id="everything-else"><h1>Everything Else</h1></a>
<p>Now we just fill in those final bits that aren't the <code>HalState</code> materials.</p>
<a class="header" href="#userinput" id="userinput"><h2><code>UserInput</code></h2></a>
<p>For input, we'll just track a few of the possible things:</p>
<ul>
<li>If a close was requested.</li>
<li>The frame's new size (if any).</li>
<li>The mouse's new position (if any).</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[derive(Debug, Clone, Default)]
pub struct UserInput {
  pub end_requested: bool,
  pub new_frame_size: Option&lt;(f64, f64)&gt;,
  pub new_mouse_position: Option&lt;(f64, f64)&gt;,
}
impl UserInput {
  pub fn poll_events_loop(events_loop: &amp;mut EventsLoop) -&gt; Self {
    let mut output = UserInput::default();
    events_loop.poll_events(|event| match event {
      Event::WindowEvent {
        event: WindowEvent::CloseRequested,
        ..
      } =&gt; output.end_requested = true,
      Event::WindowEvent {
        event: WindowEvent::Resized(logical),
        ..
      } =&gt; {
        output.new_frame_size = Some((logical.width, logical.height));
      }
      Event::WindowEvent {
        event: WindowEvent::CursorMoved { position, .. },
        ..
      } =&gt; {
        output.new_mouse_position = Some((position.x, position.y));
      }
      _ =&gt; (),
    });
    output
  }
}
#}</code></pre></pre>
<a class="header" href="#localstate" id="localstate"><h2><code>LocalState</code></h2></a>
<p>Currently, the locals are just the user input, minus the bool for if the user is
trying to quit. We'll get plenty more locals later.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[derive(Debug, Clone, Copy, Default)]
pub struct LocalState {
  pub frame_width: f64,
  pub frame_height: f64,
  pub mouse_x: f64,
  pub mouse_y: f64,
}
impl LocalState {
  pub fn update_from_input(&amp;mut self, input: UserInput) {
    if let Some(frame_size) = input.new_frame_size {
      self.frame_width = frame_size.0;
      self.frame_height = frame_size.1;
    }
    if let Some(position) = input.new_mouse_position {
      self.mouse_x = position.0;
      self.mouse_y = position.1;
    }
  }
}
#}</code></pre></pre>
<a class="header" href="#do_the_render" id="do_the_render"><h2><code>do_the_render</code></h2></a>
<p>This part is easy right now. We just make up some arbitrary color and clear the
screen to that. We'll use the mouse's position as a fraction of the total frame
size, so that the color shifts as the mouse moves. It's some sort of feedback at
least.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn do_the_render(hal_state: &amp;mut HalState, local_state: &amp;LocalState) -&gt; Result&lt;(), &amp;'static str&gt; {
  let r = (local_state.mouse_x / local_state.frame_width) as f32;
  let g = (local_state.mouse_y / local_state.frame_height) as f32;
  let b = (r + g) * 0.3;
  let a = 1.0;
  hal_state.draw_clear_frame([r, g, b, a])
}
#}</code></pre></pre>
<a class="header" href="#main" id="main"><h2><code>main</code></h2></a>
<p>Now we put it all together, and we get a final form that's pleasantly similar to
what our initial goal looked like.</p>
<pre><pre class="playpen"><code class="language-rust">fn main() {
  simple_logger::init().unwrap();

  let mut winit_state = WinitState::default();

  let mut hal_state = match HalState::new(&amp;winit_state.window) {
    Ok(state) =&gt; state,
    Err(e) =&gt; panic!(e),
  };

  let (frame_width, frame_height) = winit_state
    .window
    .get_inner_size()
    .map(|logical| logical.into())
    .unwrap_or((0.0, 0.0));
  let mut local_state = LocalState {
    frame_width,
    frame_height,
    mouse_x: 0.0,
    mouse_y: 0.0,
  };

  loop {
    let inputs = UserInput::poll_events_loop(&amp;mut winit_state.events_loop);
    if inputs.end_requested {
      break;
    }
    local_state.update_from_input(inputs);
    if let Err(e) = do_the_render(&amp;mut hal_state, &amp;local_state) {
      error!(&quot;Rendering Error: {:?}&quot;, e);
      break;
    }
  }
}
</code></pre></pre>
<p>You can find the full code file in the <code>examples/</code> directory of the repo.</p>
<a class="header" href="#triangle-intro" id="triangle-intro"><h1>Triangle Intro</h1></a>
<p>Hey, you're back.</p>
<p>This lesson builds upon the last one. Before we could draw a clear frame, now
we'll add the ability to draw a frame with a single triangle in it.</p>
<a class="header" href="#usage-code" id="usage-code"><h2>Usage Code</h2></a>
<p>Once again, even baby steps in functionality will demand pages and pages of work
to get arranged properly.</p>
<p>What we're going to write in this lesson is a single public method so that we
can draw a single triangle as a displayed frame. For now we'll stick to just
<em>one</em> triangle (three points), and even then, only a 2D triangle of <code>(x,y)</code>
points.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct Triangle {
  points: [[f32; 2]; 3]
}
#}</code></pre></pre>
<p>Why only 2D? Unfortunately, without the help of camera perspective, lightning,
shading, and other effects like that, 3D things just don't show up very well on
a 2D screen. Instead of looking like a normal triangle at an angle, it just
looks like a slightly differently shaped triangle, but still totally flat. So
when we finally transmit the triangle to the GPU we'll simply give all three
points an identical <code>z</code> coordinate for now.</p>
<p>To have some sort of confirmation of input and output like before we'll have one
of the triangle points follow the user's mouse movements. Nothing fancy, just a
way to see that we're continually  drawing a new thing each time. Actually
passing in the triangle to draw is basically identical to the clear color
function:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl HalState {
  pub fn draw_triangle_frame(&amp;mut self, triangle: Triangle) -&gt; Result&lt;(), &amp;'static str&gt; {
    unimplemented!()
  }
}
#}</code></pre></pre>
<p>The ability to draw <em>exactly one</em> triangle isn't very useful on its own. What I
mean is that we could potentially use the <code>draw_clear_frame</code> method in the
future even in a &quot;complete program&quot;. We could use it during a brief loading
screen or something. However, <code>draw_triangle_frame</code> doesn't really have a good
shelf life. In a complete program we'd want to have a way to specify an entire
scene of models, each composed of many triangles. In fact, if properly
supporting <code>draw_triangle_frame</code> in future lessons gives us any trouble at all,
we'll just delete it instead. It's seriously that impractical.</p>
<p>Why add a thing only to then take it away? Because demanding of ourselves to
draw a single triangle, of any quality, forces us to put in to place many more
parts of our overall &quot;rendering pipeline&quot;. The rendering pipeline is what's
<em>really</em> here to stay. A <strong>complete</strong> rendering pipeline with all the bells and
whistles is <em>even more complex</em> than a complete Swapchain like we did last time.
It's a many lesson long process to fully understand. In fact, the Swapchain is
one portion of the overall rendering pipeline. So we saw a bit of the whole
picture in the last lesson, we'll add more this lesson, and we'll keep expanding
and refining our process in each future lesson.</p>
<p>The entire field of 3D programming is just an unending process of learning more
and more about how you can twist the rendering pipeline to do exactly what you
want, when you want, as fast as possible.</p>
<p>If that concept doesn't excite and interest you, best to get out now. No shame
in wanting to code other parts of a program instead, but that's really all we'll
be doing, so save yourself the time if that's not what you care about.</p>
<a class="header" href="#terminology-sidebar-immediate-vs-retained" id="terminology-sidebar-immediate-vs-retained"><h3>Terminology Sidebar: Immediate vs Retained</h3></a>
<p>As we go further I should probably define two terms you might see come up here
or in other graphics tutorials: Immediate API and Retained API.</p>
<ul>
<li>An immediate API is any API where you call a function with an argument and it
does all the work with that argument right then, without storing the argument
data for later.</li>
<li>A retained API is any API where your function calls cause data to be
<em>retained</em> by the system. Usually you make some calls to set up the situation,
and then you make a separate call to compute things using the requested setup.</li>
</ul>
<p>In general, an immediate API is often easier to use, but a retained API is often
more efficient if the input format and usage format differ (so you don't have to
convert more than once) or if the system needs special resources (heap
allocation, open file handles, things like that).</p>
<a class="header" href="#quick-bug-fixes" id="quick-bug-fixes"><h2>Quick Bug Fixes</h2></a>
<p>There's two things we have to change about last lesson's code before we proceed
to mostly work on new code.</p>
<a class="header" href="#that-swapchain-is-too-big" id="that-swapchain-is-too-big"><h3>That Swapchain Is Too Big!</h3></a>
<p>On the Metal backend (mac os) the extent that's reported in the swapchain
capabilities isn't clamped to the window size, so you get a reported maximum
size of 4096 x 4096. Obviously that's far too big! It doesn't matter for just
clearing the screen, but it matters now that we'll be drawing something.</p>
<p>We just have to edit how we define the extent as we create our Swapchain:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
let extent = {
  let window_client_area = window.get_inner_size().ok_or(&quot;Window doesn't exist!&quot;)?;
  Extent2D {
    width: caps.extents.end.width.min(window_client_area.width as u32),
    height: caps.extents.end.height.min(window_client_area.height as u32),
  }
};
#}</code></pre></pre>
<a class="header" href="#the-swapchain-doesnt-resize" id="the-swapchain-doesnt-resize"><h3>The Swapchain Doesn't Resize!</h3></a>
<p>The window can resize, but the backing swapchain doesn't resize. Again, this
isn't apparent when you're drawing nothing, but once you draw something it'll be
drawing at the starting resolution and then scaling up or down to the window's
real size.</p>
<p>Now, you <em>could</em> try to carefully destroy anything that came from the Swapchain
and then the Swapchain itself and then re-create each element at the new size.
You could, it'd work.</p>
<p>Why bother being so fiddly though? We've gone to all the work of making our
<code>HalState</code> type very cleanly close itself down. Let's take advantage of that and
just throw out the <em>entire</em> old <code>HalState</code> and build a new one. We don't have to
think about what the ordering of anything is, we don't have to remember to
update the change_resolution code every time we touch some other part of the
code. It's really so much less error prone. &quot;Just restart the whole thing&quot; is
how you get that magical <a href="https://en.wikipedia.org/wiki/Erlang_(programming_language)">Nine Nines
Stability</a>, after
all ;3</p>
<p>Note that we need to restart hal if we detect a window size change, but <em>also</em>
if we're using <code>Mailbox</code> mode it's possible for the GPU to try and present a
frame in the moment between when the window resizes and when we detect the error
and respond. To cover this case, we'll also try to restart hal if we get any
rendering error.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
loop {
  let inputs = UserInput::poll_events_loop(&amp;mut winit_state.events_loop);
  if inputs.end_requested {
    break;
  }
  if inputs.new_frame_size.is_some() {
    debug!(&quot;Window changed size, restarting HalState...&quot;);
    drop(hal_state);
    hal_state = match HalState::new(&amp;winit_state.window) {
      Ok(state) =&gt; state,
      Err(e) =&gt; panic!(e),
    };
  }
  local_state.update_from_input(inputs);
  if let Err(e) = do_the_render(&amp;mut hal_state, &amp;local_state) {
    error!(&quot;Rendering Error: {:?}&quot;, e);
    debug!(&quot;Auto-restarting HalState...&quot;);
    drop(hal_state);
    hal_state = match HalState::new(&amp;winit_state.window) {
      Ok(state) =&gt; state,
      Err(e) =&gt; panic!(e),
    };
  }
}
#}</code></pre></pre>
<p>Now <strong>please</strong> be aware that this isn't actually the best design for every
possible <code>gfx-hal</code> program! It's just the best way to do it for our small
program here. The more data that you've uploaded to the GPU that you want to
preserve, the more you might want to consider rebuilding just a small number of
parts. It's something you have to investigate for yourself as your program
grows.</p>
<a class="header" href="#drawing-a-triangle" id="drawing-a-triangle"><h1>Drawing A Triangle</h1></a>
<p>To draw a triangle, we will use the same sort of setup before, with the frame
based drawing and the &quot;ring buffer&quot; vectors of all our tools. Literally just
copy and paste all of <code>draw_clear_frame</code> to a new spot and name it
<code>draw_triangle_frame</code>, the bulk of it is that similar. The argument is a single
triangle instead of a single color though.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub fn draw_triangle_frame(&amp;mut self, triangle: Triangle) -&gt; Result&lt;(), &amp;'static str&gt; {
#}</code></pre></pre>
<p>Now you'd think &quot;hey can't we abstract the commonalities here? Well, maybe but
you can't really do it with a function and a closure because lifetimes and
function borders don't play particularly nice in Rust. Our draw code
unfortunately really relies on having a lot of &quot;split borrows&quot; (where the borrow
is just on one field at a time) instead of struct-wide borrows (eg: <code>&amp;self</code> or
<code>&amp;mut self</code>). Or you could do it as a macro maybe? Either way it'd be probably
quite a bit of work for not too much gained. We don't want to over abstract
until we see how the code is growing.</p>
<a class="header" href="#upload-that-triangle-data" id="upload-that-triangle-data"><h2>Upload That Triangle Data</h2></a>
<p>To actually place data for the triangle into the vertex buffer we need a mapping
writer. Unfortunately, this is <em>basically</em> a reference, which means that it has
a lifetime linked to a particular blob of <code>Memory</code> from the GPU, which means
that we can't really store it in the same struct that holds the handle to the
Memory because Rust is just bad at self-referential struct things. Instead,
we'll get a mapping writer, use it, and then destroy it.</p>
<p>(Hint: if you already read <a href="https://doc.rust-lang.org/nomicon/">The
Rustonomicon</a> like I told you to in the
Introduction, then you already know how to cheese it and avoid this limitation
at the small cost of <em>massive</em> unsafety, should you want to. If you need <em>me</em> to
tell you how, then you're not ready to do it.)</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // WRITE THE TRIANGLE DATA
    unsafe {
      let mut data_target = self
        .device
        .acquire_mapping_writer(&amp;self.memory, 0..self.requirements.size)
        .map_err(|_| &quot;Failed to acquire a memory writer!&quot;)?;
      let points = triangle.points_flat();
      data_target[..points.len()].copy_from_slice(&amp;points);
      self
        .device
        .release_mapping_writer(data_target)
        .map_err(|_| &quot;Couldn't release the mapping writer!&quot;)?;
    }
#}</code></pre></pre>
<p>As you'll see in future lessons, it's actually very rare to update all the
vertex data of a model every frame. Usually you set it once and then use
&quot;transforms&quot; to move the model around within the scene, without actually
affecting the vertex data. For now, we'll just push fresh vertex data each
frame.</p>
<a class="header" href="#record-the-commands" id="record-the-commands"><h2>Record The Commands</h2></a>
<p>All that really changes here compared to <code>draw_clear_frame</code> is that instead of
starting a CommandBuffer and then recording <em>nothing</em>, we'll actually record
something this time.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // RECORD COMMANDS
    unsafe {
      let buffer = &amp;mut self.command_buffers[i_usize];
      const TRIANGLE_CLEAR: [ClearValue; 1] = [ClearValue::Color(ClearColor::Float([0.1, 0.2, 0.3, 1.0]))];
      buffer.begin(false);
      {
        let mut encoder = buffer.begin_render_pass_inline(
          &amp;self.render_pass,
          &amp;self.framebuffers[i_usize],
          self.render_area,
          TRIANGLE_CLEAR.iter(),
        );
        encoder.bind_graphics_pipeline(&amp;self.graphics_pipeline);
        // Here we must force the Deref impl of ManuallyDrop to play nice.
        let buffer_ref: &amp;&lt;back::Backend as Backend&gt;::Buffer = &amp;self.buffer;
        let buffers: ArrayVec&lt;[_; 1]&gt; = [(buffer_ref, 0)].into();
        encoder.bind_vertex_buffers(0, buffers);
        encoder.draw(0..3, 0..1);
      }
      buffer.finish();
    }
#}</code></pre></pre>
<p>This time out the mouse will control one of the triangle points instead of the
color, so we'll pick a fixed color for the clear color. Once we start the
&quot;render pass inline&quot; we're actually going to bind what we get back from that.
It's a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/command/struct.RenderPassInlineEncoder.html">RenderPassInlineEncoder</a>,
which is also
Deref&lt;Target=<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/command/struct.RenderSubpassCommon.html">RenderSubpassCommon</a>&gt;,
and it gives us access to the operations of a particular render pass.</p>
<ul>
<li><a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/command/struct.RenderSubpassCommon.html#method.bind_graphics_pipeline">RenderSubpassCommon::bind_graphics_pipeline</a>
picks a particular graphics pipeline for the rendering of this subpass. You
<em>can</em> have more than one graphics pipeline, each with its own settings, if you
want, though while we're starting out we only need one per program.</li>
<li><a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/command/struct.RenderSubpassCommon.html#method.bind_vertex_buffers">RenderSubpassCommon::bind_vertex_buffers</a>
picks the vertex buffers to use for this subpass. The magical looking <code>0</code> here
has to match up with the
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.VertexBufferDesc.html">VertexBufferDesc</a>
that's specified as part of the graphics pipeline that you're using. We'll
talk about the full graphics pipeline definition in a moment, but the thing to
pay attention to right now is that you can have many buffers and you don't
need to specify them all in a single bind call. You could give 3 starting at
0, give 3 more starting at 3, etc. We only have one buffer, so we just need
one bind call and we place it at the 0th index.</li>
<li><a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/command/struct.RenderSubpassCommon.html#method.draw">RenderSubpassCommon::draw</a>
uses Range properly, so those really are exclusive endings. This uses our
three vertices (indexed 0, 1, 2) and a single instance (indexed 0). The
instance thing has to do with a more advanced technique called &quot;instanced
drawing&quot; where you can draw a particular setup many times as a single draw
call, specifying parameters per instance. That'd be for something like drawing
ten copies of the same tree model, each in their own position and orientation
within the scene. There's a small price per draw call that you make, so if
you're drawing &quot;the same&quot; thing many times with small variation it pays off to
setup instanced drawing and make a single draw call with many instances
specified. We'll cover all that more in a future lesson. For now we've just
got a single triangle as part of a single instance.</li>
</ul>
<p>That's all we gotta do!</p>
<p>&quot;all&quot;</p>
<p>What comes next is setting up the graphical pipeline to make this happen.</p>
<a class="header" href="#define-a-graphics-pipeline" id="define-a-graphics-pipeline"><h1>Define A Graphics Pipeline</h1></a>
<p>I know that in the last lesson we did all of our setup without any of the code
being placed into helper functions, and I stand by that. None of it was super
complex (honest!) and most of the sub-parts weren't ever going to be called in
different contexts with different inputs. Most of the time you want to make
something a function when you're going to reuse it, not just because it's long.</p>
<p>This time I'm going to bend on that, because the graphics pipeline setup is
about 2/3rds as long as <em>all of</em> the initialization setup that we did before.
It's not even super complex, there's just a billion little settings and options
that we have to specify.</p>
<a class="header" href="#create_pipeline-signature" id="create_pipeline-signature"><h2><code>create_pipeline</code> Signature</h2></a>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  #[allow(clippy::type_complexity)]
  fn create_pipeline(
    device: &amp;mut back::Device, extent: Extent2D, render_pass: &amp;&lt;back::Backend as Backend&gt;::RenderPass,
  ) -&gt; Result&lt;
    (
      Vec&lt;&lt;back::Backend as Backend&gt;::DescriptorSetLayout&gt;,
      &lt;back::Backend as Backend&gt;::PipelineLayout,
      &lt;back::Backend as Backend&gt;::GraphicsPipeline,
    ),
    &amp;'static str,
  &gt; {
#}</code></pre></pre>
<p>Okay, ha, so, what have we got here. First, we're telling clippy to please stay
calm despite the very complex return type there. It wants us to make a
<code>Result&lt;Struct, &amp;str&gt;</code>, and I won't say it's wrong, it's just not what I wanna
do with my time right now. We'll just use a 3-tuple.</p>
<p>So what does our pipeline need for us to get our Result? First of all, let's be
<em>super</em> clear if it wasn't clear enough already from the tuple: The &quot;pipeline&quot;
is actually three different parts, <em>one of which</em> is a thing that's actually
called GraphicsPipeline, but also we need to know the PipelineLayout that goes
with it, as well as the DescriptorSetLayout. I'd love to link you to some docs
for these types, but the specifics of all three are Backend dependent. We just
take it on faith that they do something important, without yet knowing what they
do precisely.</p>
<p>If we review the
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/device/trait.Device.html">Device</a> trait
we'll see that each of these things comes from a <code>create_foo</code> method on the
Device, so we'll need to add them to the Drop code for <code>HalState</code>. I'll assume
that you can do that yourself by now, you just do the same thing as before. 1)
store it as a ManuallyDrop, 2) use <code>read</code> to pseudo-clone it and then pass that
pseudo-clone to the <code>destroy_foo</code> method.</p>
<p>So we need <code>&amp;mut Device</code> as an input. We also need the <code>Extent2D</code> for what size
of Swapchain this pipeline setup goes with. Finally, we need a <code>&amp;RenderPass</code>.
The sub-passes of the pipeline we make will need to be able to reference back to
it during the setup.</p>
<p>So we want to make a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.GraphicsPipelineDesc.html">GraphicsPipelineDesc</a>,
but as you can see there's 13 fields there, so we'll have to handle a few at a
time until everything is ready.</p>
<a class="header" href="#shader-modules" id="shader-modules"><h2>Shader Modules</h2></a>
<p>A <strong>Shader</strong> is one of several parts of the graphical pipeline on the GPU.
There's several stages of shader, as well as some non-shader stages. Right here
I'm going to go ahead and use a graphic from the <a href="https://vulkan-tutorial.com/Drawing_a_triangle/Graphics_pipeline_basics">Graphics Pipeline
Basics</a>
potion of the <a href="vulkan-tutorial.com">vulkan-tutorial.com</a> tutorial, because
they've got a pretty slick diagram of it.</p>
<p><img src="https://vulkan-tutorial.com/images/vulkan_simplified_pipeline.svg" alt="pipeline-diagram" /></p>
<p>Things in <em>green</em> are selections we can make, but from only a limited list of
options. Things in <em>yellow</em> are things that we can write a shader for.</p>
<p>A shader is a mini-program (sometimes not so mini) that has its own options for
source language, and it's own compiled format, and all of that. Instead of
writing in Rust and compiling to <code>ARM</code> or <code>x86_64</code> or something else, we write a
program in <a href="https://en.wikipedia.org/wiki/OpenGL_Shading_Language">GLSL</a> and
compile it to <a href="https://www.khronos.org/registry/spir-v/">SPIRV</a>. Actually you
can write a shader in anything that compiles to compatible SPIRV code, but the
tools that are easiest for us to use right now do GLSL -&gt; SPIRV.</p>
<p>A <strong>Shader Module</strong> is a handle that you get when you upload some shader code to
the GPU. We take a few shader modules and put them together into a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.GraphicsShaderSet.html">GraphicsShaderSet</a>.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    let mut compiler = shaderc::Compiler::new().ok_or(&quot;shaderc not found!&quot;)?;
    let vertex_compile_artifact = compiler
      .compile_into_spirv(VERTEX_SOURCE, shaderc::ShaderKind::Vertex, &quot;vertex.vert&quot;, &quot;main&quot;, None)
      .map_err(|_| &quot;Couldn't compile vertex shader!&quot;)?;
    let fragment_compile_artifact = compiler
      .compile_into_spirv(FRAGMENT_SOURCE, shaderc::ShaderKind::Fragment, &quot;fragment.frag&quot;, &quot;main&quot;, None)
      .map_err(|e| {
        error!(&quot;{}&quot;, e);
        &quot;Couldn't compile fragment shader!&quot;
      })?;
    let vertex_shader_module = unsafe {
      device
        .create_shader_module(vertex_compile_artifact.as_binary_u8())
        .map_err(|_| &quot;Couldn't make the vertex module&quot;)?
    };
    let fragment_shader_module = unsafe {
      device
        .create_shader_module(fragment_compile_artifact.as_binary_u8())
        .map_err(|_| &quot;Couldn't make the fragment module&quot;)?
    };
#}</code></pre></pre>
<p>For this to work, you have to use the <code>shaderc-rs</code> crate, which takes <em>very</em>
long to build that first time because it's actually just using <code>build.rs</code> to
download a C++ program and build that. The <code>shaderc</code> crate is just a fairly thin
wrapper over accessing those C++ programs. In fact, if you wanted to ship this
code to someone it wouldn't work if they didn't also have shaderc-rs installed.
Don't worry, you can pre-compile the shader code and just ship those byte blobs
directly, then they wouldn't need the compilers installed. You usually don't
need to change your shader code at runtime, so it's not a very big deal. This is
another one of those areas where it's very much a &quot;too early to be easy to use&quot;
situation.</p>
<ol>
<li>We open a compiler</li>
<li>We compile some Vertex Shader source. This is &quot;where do the points go on the
screen&quot;. We use a string literal in our file, the shader type we want, a
dummy file name (it's just used for error messages), the &quot;entry point&quot; of the
program, and finally we could give some extra options if we wanted.</li>
<li>Then we do the exact same thing for the Fragment Shader. This is &quot;what color
are the points&quot;.</li>
</ol>
<p>To form a GraphicsShaderSet you <em>always</em> need a vertex shader, and then all the
other types are optional. However, to form an image you always must include a
fragment shader or all the color output is undefined (hard to have an image
without any colors). There <em>are</em> things you can do with a GraphicsShaderSet
where you don't need a fragment shader because you don't use the color channel
output, but those are for some future lesson.</p>
<p>In fact, shaders are complex enough that we'll spend the next lesson on a proper
shader introduction, and I'm going to punt all the rest of the description about
them until that lesson.</p>
<p>The last thing to say here is that the shader modules need to be destroyed, but
we don't need to store them forever in the <code>HalState</code>. We can destroy them after
we've made our graphics pipeline parts but before <code>create_pipeline</code> returns.
Once they've been incorporated into the pipeline we don't need to hold on to the
individual handles any more.</p>
<a class="header" href="#make-a-graphicsshaderset" id="make-a-graphicsshaderset"><h2>Make A GraphicsShaderSet</h2></a>
<p>Next, we go into one of those inner scopes that we love to use. Don't you love
'em? I sure do. Scopes for days. In this case, the point here is that we're
separating off all the stuff that happens while we've got those shader modules
created.</p>
<p>To make a GraphicsShaderSet we need an
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.EntryPoint.html">EntryPoint</a>
for each shader. It needs the <code>entry</code> (which matches the entry defined in the
compiled SPIRV code), the shader module, and a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.Specialization.html">Specialization</a>,
which we won't use right now (we'll just give empty slices).</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let (vs_entry, fs_entry) = (
        EntryPoint {
          entry: &quot;main&quot;,
          module: &amp;vertex_shader_module,
          specialization: Specialization {
            constants: &amp;[],
            data: &amp;[],
          },
        },
        EntryPoint {
          entry: &quot;main&quot;,
          module: &amp;fragment_shader_module,
          specialization: Specialization {
            constants: &amp;[],
            data: &amp;[],
          },
        },
      );
      let shaders = GraphicsShaderSet {
        vertex: vs_entry,
        hull: None,
        domain: None,
        geometry: None,
        fragment: Some(fs_entry),
      };
#}</code></pre></pre>
<a class="header" href="#input-assembler" id="input-assembler"><h2>Input Assembler</h2></a>
<p>Once we've got all of our shader stuff arranged, we need to define all the other
parts. The first thing up (going in order of the pipeline diagram) is the
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.InputAssemblerDesc.html">InputAssemblerDesc</a>,
where we pick a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/enum.Primitive.html">Primitive</a> for how
our vertices will be treated. The vertices are really just a huge list of values
(usually <code>f32</code>, but even then not always), and you have to tell the system how
it's supposed to turn those values into geometry. You should check the <a href="https://vulkan.lunarg.com/doc/view/1.0.33.0/linux/vkspec.chunked/ch19s01.html">vulkan
docs</a>
on this one, because they really get into it with diagrams and everything, but
here's the short version:</p>
<ul>
<li>As you expect, there's triangles, but you can also specify lines and points.</li>
<li>Geometry can be given as a &quot;list&quot;, where each unit is totally unique, or as a
&quot;strip&quot; where successive units share some vertex data. This can be trickier to
arrange until you get used to it, but it saves on data uploaded and data
stored. Even as desktops move to having 8GB or 16GB of RAM, the GPU itself has
half (or less!) of that, so making your models &quot;compressed&quot; like this is very
nice.</li>
</ul>
<a class="header" href="#vertex-shader" id="vertex-shader"><h2>Vertex Shader</h2></a>
<p>I know that we already have a shader module for our vertex shader, but we also
need to specify what buffers are going to be serving up vertex data, as well as
the attributes for the data. I said that the vertex data is actually just a huge
list of values, but those values aren't <em>only</em> positions for each vertex. You
most commonly will specify color and/or texture info as well as position
information.</p>
<p>Well, you <em>would</em> if you were doing a bigger example than this. To start we're
doing a single monochrome triangle, so we'll just have each vertex specify an
<code>(x,y)</code> position.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let vertex_buffers: Vec&lt;VertexBufferDesc&gt; = vec![VertexBufferDesc {
        binding: 0,
        stride: (size_of::&lt;f32&gt;() * 2) as u32,
        rate: 0,
      }];
      let attributes: Vec&lt;AttributeDesc&gt; = vec![AttributeDesc {
        location: 0,
        binding: 0,
        element: Element {
          format: Format::Rg32Float,
          offset: 0,
        },
      }];
#}</code></pre></pre>
<p>For the
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.VertexBufferDesc.html">VertexBufferDesc</a>
we give:</p>
<ul>
<li>A <code>binding</code> index: remember that &quot;magical 0&quot; I mentioned we used when we wrote
the CommandBuffer? That's this thing.</li>
<li>A <code>stride</code>: how much space, in bytes, between the start of one vertex data
blob and the next</li>
<li>A <code>rate</code>: which is for that instanced drawing thing that I said we'd do in a
future lessons).
We need one of these descriptions <em>per vertex buffer</em>.</li>
</ul>
<p>For the
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.AttributeDesc.html">AttributeDesc</a>
we give</p>
<ul>
<li>A <code>location</code>: which will match up with locations specified for inputs in our
shader code. They're counted up from 0, like array indexes.</li>
<li>A <code>binding</code>: which matches up with the VertexBufferDesc that this
AttributeDesc is for. Each VertexBufferDesc can have its own attribute
arrangement if you like, it can get quite intricate.</li>
<li>An <code>element</code>: This is an
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.Element.html">Element</a>
entry, which gives the
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/format/enum.Format.html">Format</a> of the
particular attribute, as well as the byte offset for how far into the vertex
entry this particular attribute starts. The formats are mostly all specified
in terms of what sort of color data format they'd give, so &quot;two f32 values&quot; is
<code>Rg32Float</code>, even though we won't be using them as red and green channel data.
This is one of those things where you just have to accept that bits are bits
and the meaning is more what you make of it.</li>
</ul>
<a class="header" href="#tessellation-shader" id="tessellation-shader"><h2>Tessellation Shader</h2></a>
<p>We don't do anything here! Freebie! This <em>would</em> break up geometry into smaller
geometry to add apparent details, but we're not gonna right now.</p>
<a class="header" href="#geometry-shader" id="geometry-shader"><h2>Geometry Shader</h2></a>
<p>We also don't do anything here! Another freebie! This <em>would</em> let us process
each geometry item (point/line/triangle) into either 0 outputs (canceling that
item), 1 output, or even more than one output (kinda like the tessellation
shader).</p>
<a class="header" href="#rasterization" id="rasterization"><h2>Rasterization</h2></a>
<p>Once we have all of our geometry arranged, we need to translate the points into
pixels on the screen. So we specify a <a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.Rasterizer.html">Rasterizer</a>:</p>
<ul>
<li><code>polygon_mode</code>: Pick a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/enum.PolygonMode.html">PolygonMode</a>.
Usually you want <code>Fill</code>, though <code>Line</code> and <code>Point</code> are neat for &quot;debug
display&quot; sorts of things. Or if you want to go for the &quot;Tron&quot; look.</li>
<li><code>cull_face</code>: When you define a triangle, it's obviously got two sides (called
&quot;front&quot; and &quot;back&quot;). You can make it so that if a triangle is viewed from the
&quot;wrong&quot; side then it's not included in the output.</li>
<li><code>front_face</code>: The &quot;front&quot; of the triangle depends on the order that the vertex
data is specified, it can be &quot;clockwise&quot; or &quot;counterclockwise&quot; (that's
&quot;widdershins&quot; for all our UK friends). This decision is basically arbitrary,
your models can go either way as long as they match what you define here.</li>
<li><code>depth_clamping</code>: If a thing is off the screen in X or Y we're not going to
see it, but what about the Z direction? If this is false then things that are
&quot;out of bounds&quot; in the Z direction get culled. If this is true then they get
their Z position clamped, so they end up included in the output.</li>
<li><code>depth_bias</code>: An optional parameter that's for when you need to draw things
very closely to one other in the Z direction. Without this you can get a very
bad looking effect called &quot;z-fighting&quot; where two elements become incorrectly
mixed together visually
(<a href="http://farm8.staticflickr.com/7355/8872454389_b82ae11d77_o.png">pic</a>). This
lets you apply some <a href="https://www.khronos.org/registry/vulkan/specs/1.0/html/vkspec.html#primsrast-depthbias">complicated
math</a>
to compensate for such a situation. Another one of those &quot;we'll get to it
later&quot; things, so we specify <code>None</code> to start.</li>
<li><code>conservative</code>: This is a <a href="https://developer.nvidia.com/content/dont-be-conservative-conservative-rasterization">neat graphics
extension</a>
that basically lets more fragments be generated per geometry unit, which can
lead to a much better result, because the output appears more &quot;smoothly&quot; (see
the pics in that article to understand what I'm trying to say). There's
probably a reasonable number of GPUs that might be running gfx-hal that
<em>wouldn't</em> support this extension though, so we won't request it starting out,
because with just one triangle it doesn't make a difference in the scene.</li>
</ul>
<a class="header" href="#fragment-shader" id="fragment-shader"><h2>Fragment Shader</h2></a>
<p>So the rasterizer turned all of our geometry elements into pixel locations for
us, now the final shader runs. It takes &quot;some data&quot; and picks a color for this
&quot;fragment&quot;. A fragment is like a <em>part</em> of a pixel. Depending on the full scene,
more than one fragment can end up in the same pixel, and then they'll get
blended together. You don't know what the pixel will finally be until all of the
fragments that touch that pixel are done.</p>
<p>The actual data that the fragment shader gets is mostly whatever the previous
stages of the pipeline have output. There's no specific format and there's no
&quot;FragmentShaderDesc&quot; type that you set up on the CPU side. It's all defined in
your shader files. Any per-fragment values have to come through the previous
stages of the pipeline, starting back at the Vertex Shader. There is the ability
to have global, read only data (as a Push Constant or Uniform), but any
per-fragment data has to come through the whole pipeline process.</p>
<p>A single geometry element can have many fragments. Imagine a triangle that goes
from the bottom left, to the top left, to the top right. There's only three
vertices, but <em>half the screen</em> is covered in fragments. The pipeline
automatically interpolates the values for any fragment that's not directly from
a vertex (which is almost every fragment ever, honestly). That might sound kinda
spooky, but the weird part is that it works really well even once textures and
stuff are involved.</p>
<a class="header" href="#multisampling" id="multisampling"><h3>Multisampling</h3></a>
<p>Sometimes you'll get edges in your pictures that look &quot;jagged&quot;. The eyes can
pick up where a long line is jumping from one pixel to the next if it's almost
but not quite vertical or horizontal. Fixing that is called &quot;anti-aliasing&quot;, and
there's more than one way to do it.</p>
<p>The pipeline in <code>gfx-hal</code> has a parameter for &quot;multisampling&quot;, where instead of
computing fragments on a pixel basis, you compute them on a sub-pixel basis and
average the results. You're basically just throwing computational power at the
problem to try and get a more accurate result. Naturally, if you do enable
multisampling, you want to allow for a user to turn such a feature off if they
don't have as good of a graphics card. We won't enable it for now, because
adding it in touches just a little bit of the swapchain, the render pass, the
pipeline, anything that has to do with images. We can do that as lesson of its
own soon.</p>
<a class="header" href="#depth-testing" id="depth-testing"><h3>Depth Testing</h3></a>
<p>This is actually not <em>specifically</em> part of the fragment shader, it's a step
after the fragment shader but before the color blending. There's no space for
that on our handy diagram, so we'll talk about it right here. Basically, in
addition to having colors, an image also has depth values for each pixel (we've
touched on this a bit before). After a fragment shader runs and <em>would</em> perform
a change there's a depth test, and you can determine what actual change, if any,
goes into effect. Or you can enable <a href="http://vulkan-spec-chunked.ahcox.com/ch25s04.html">early fragment test
mode</a> if you want, it's one
of <a href="http://vulkan-spec-chunked.ahcox.com/ch25s01.html">many operations</a> that can
potentially discard a fragment.</p>
<p>As you're probably getting sick of hearing at this point, we're not using depth
testing right now.</p>
<p>Note that there's two different structs called <code>DepthStencilDesc</code> in the
<code>gfx-hal</code> crate. The one in the <code>image</code> module is deprecated old nonsense, we
want to be sure to import the one from the <code>pso</code> module.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let depth_stencil = DepthStencilDesc {
        depth: DepthTest::Off,
        depth_bounds: false,
        stencil: StencilTest::Off,
      };
#}</code></pre></pre>
<a class="header" href="#color-blending" id="color-blending"><h2>Color Blending</h2></a>
<p>The final stage is color blending. Since we're doing 3d graphics, sometimes one
thing will need to appear &quot;in front of&quot; another. If it's fully opaque you just
draw the closer thing, but sometimes you get fragments that aren't fully opaque,
and so you blend the closer and farther thing. We can describe how we want that
to happen.</p>
<p>Except we're not doing blending stuff so we're going to totally ignore the
&quot;current destination value&quot; and only take the &quot;source value&quot;.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let blender = {
        let blend_state = BlendState::On {
          color: BlendOp::Add {
            src: Factor::One,
            dst: Factor::Zero,
          },
          alpha: BlendOp::Add {
            src: Factor::One,
            dst: Factor::Zero,
          },
        };
        BlendDesc {
          logic_op: Some(LogicOp::Copy),
          targets: vec![ColorBlendDesc(ColorMask::ALL, blend_state)],
        }
      };
#}</code></pre></pre>
<a class="header" href="#more-things-to-define" id="more-things-to-define"><h2>More Things To Define</h2></a>
<p>You thought we were done! Ha, if only.</p>
<a class="header" href="#bakedstates" id="bakedstates"><h3>BakedStates</h3></a>
<p>We need to define</p>
<ul>
<li><code>viewport</code>: Defines part of the whole
<a href="https://renderdoc.org/vkspec_chunked/chap25.html#vertexpostproc-viewport">viewport</a>
process. Right now <code>gfx-hal</code> doesn't support more than one viewport, but it's
on the list of TODOs for 0.2.</li>
<li><code>scissor</code>: Defines the params for the <a href="https://renderdoc.org/vkspec_chunked/chap27.html#fragops-scissor">scissor
test</a>, which
takes in 2d framebuffer coordinates and cancels a fragment if it falls outside
the scissor area. This is also going to eventually allow for more than one
scissor areas, but it's not there yet.</li>
<li><code>blend_color</code>: This is a static color to blend over the whole image. You
probably don't want this most of the time, since it's baked into the whole
pipeline. For dynamic color blend effects (eg: flashing the screen red when an
attack hits) you'd put that in as part of your fragment shader.</li>
<li><code>depth_bounds</code>: This defines the limits of that depth test thing.</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let baked_states = BakedStates {
        viewport: Some(Viewport {
          rect: extent.to_extent().rect(),
          depth: (0.0..1.0),
        }),
        scissor: Some(extent.to_extent().rect()),
        blend_color: None,
        depth_bounds: None,
      };
#}</code></pre></pre>
<a class="header" href="#non-buffer-data-sources" id="non-buffer-data-sources"><h3>Non-Buffer Data Sources</h3></a>
<p>Data for the graphics pipeline <em>can</em> come from things other than the vertex
buffer. We're not doing that here, but we still have to <em>say</em> that we're not
doing it here.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let bindings = Vec::&lt;DescriptorSetLayoutBinding&gt;::new();
      let immutable_samplers = Vec::&lt;&lt;back::Backend as Backend&gt;::Sampler&gt;::new();
      let descriptor_set_layouts: Vec&lt;&lt;back::Backend as Backend&gt;::DescriptorSetLayout&gt; = vec![unsafe {
        device
          .create_descriptor_set_layout(bindings, immutable_samplers)
          .map_err(|_| &quot;Couldn't make a DescriptorSetLayout&quot;)?
      }];
      let push_constants = Vec::&lt;(ShaderStageFlags, core::ops::Range&lt;u32&gt;)&gt;::new();
      let layout = unsafe {
        device
          .create_pipeline_layout(&amp;descriptor_set_layouts, push_constants)
          .map_err(|_| &quot;Couldn't create a pipeline layout&quot;)?
      };
#}</code></pre></pre>
<a class="header" href="#graphics-pipeline" id="graphics-pipeline"><h2>Graphics Pipeline</h2></a>
<p>We can finally, <em>finally</em> make that graphics pipeline. We use all the stuff
declared so far, and a few more filler arguments that are unimportant to us
right now, to make a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/pso/struct.GraphicsPipelineDesc.html">GraphicsPipelineDesc</a>.
That gets passed to
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/device/trait.Device.html#method.create_graphics_pipeline">Device::create_graphics_pipeline</a>.
We could optionally specify a pipeline cache too, but we don't have such a thing
yet.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let gfx_pipeline = {
        let desc = GraphicsPipelineDesc {
          shaders,
          rasterizer,
          vertex_buffers,
          attributes,
          input_assembler,
          blender,
          depth_stencil,
          multisampling: None,
          baked_states,
          layout: &amp;layout,
          subpass: Subpass {
            index: 0,
            main_pass: render_pass,
          },
          flags: PipelineCreationFlags::empty(),
          parent: BasePipeline::None,
        };

        unsafe {
          device
            .create_graphics_pipeline(&amp;desc, None)
            .map_err(|_| &quot;Couldn't create a graphics pipeline!&quot;)?
        }
      };
#}</code></pre></pre>
<a class="header" href="#backing-out-of-create_pipeline" id="backing-out-of-create_pipeline"><h2>Backing Out Of <code>create_pipeline</code></h2></a>
<p>Once that's done we go up a level, destroy our shader modules, and then return
what we've built to the caller.</p>
<a class="header" href="#define-a-buffer-for-vertex-data" id="define-a-buffer-for-vertex-data"><h1>Define A Buffer For Vertex Data</h1></a>
<p>So within <code>HalState::new</code> we've made some pipeline bits:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // Build our pipeline and vertex buffer
    let (descriptor_set_layouts, pipeline_layout, graphics_pipeline) = Self::create_pipeline(&amp;mut device, extent, &amp;render_pass)?;
#}</code></pre></pre>
<p>It said that it's going to use a buffer, but we need to make that buffer separately.</p>
<a class="header" href="#make-a-buffer-and-some-memory" id="make-a-buffer-and-some-memory"><h2>Make A Buffer And Some Memory</h2></a>
<p>First we ask the Device to please make us a Buffer, which is basically just
another &quot;handle&quot; thing.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      const F32_XY_TRIANGLE: u64 = (size_of::&lt;f32&gt;() * 2 * 3) as u64;
      let mut buffer = device
        .create_buffer(F32_XY_TRIANGLE, BufferUsage::VERTEX)
        .map_err(|_| &quot;Couldn't create a buffer for the vertices&quot;)?;
#}</code></pre></pre>
<p>Now that we have a buffer we can ask what the requirements for the buffer are.
It might seem strange to make a thing and <em>then</em> ask what the requirements for it
are, but that's how you do it.</p>
<p>Using the requirements we can get a &quot;memory type ID&quot;, which allows us to
allocate some memory to go with this buffer. It's certainly some <em>weird</em> looking
code, but just go with it.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let requirements = device.get_buffer_requirements(&amp;buffer);
      let memory_type_id = adapter
        .physical_device
        .memory_properties()
        .memory_types
        .iter()
        .enumerate()
        .find(|&amp;(id, memory_type)| {
          requirements.type_mask &amp; (1 &lt;&lt; id) != 0 &amp;&amp; memory_type.properties.contains(Properties::CPU_VISIBLE)
        })
        .map(|(id, _)| MemoryTypeId(id))
        .ok_or(&quot;Couldn't find a memory type to support the vertex buffer!&quot;)?;
      let memory = device
        .allocate_memory(memory_type_id, requirements.size)
        .map_err(|_| &quot;Couldn't allocate vertex buffer memory&quot;)?;
#}</code></pre></pre>
<p>And once that is allocated, we can bind the buffer to the memory that goes with
it.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      device
        .bind_buffer_memory(&amp;memory, 0, &amp;mut buffer)
        .map_err(|_| &quot;Couldn't bind the buffer memory!&quot;)?;
#}</code></pre></pre>
<a class="header" href="#update-the-halstate-struct" id="update-the-halstate-struct"><h2>Update The <code>HalState</code> Struct</h2></a>
<p>With these new things in hand, we need to add to the <code>struct</code> definition</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct HalState {
  buffer: ManuallyDrop&lt;&lt;back::Backend as Backend&gt;::Buffer&gt;,
  memory: ManuallyDrop&lt;&lt;back::Backend as Backend&gt;::Memory&gt;,
  descriptor_set_layouts: Vec&lt;&lt;back::Backend as Backend&gt;::DescriptorSetLayout&gt;,
  pipeline_layout: ManuallyDrop&lt;&lt;back::Backend as Backend&gt;::PipelineLayout&gt;,
  graphics_pipeline: ManuallyDrop&lt;&lt;back::Backend as Backend&gt;::GraphicsPipeline&gt;,
  requirements: Requirements,
  current_frame: usize,
  frames_in_flight: usize,
  in_flight_fences: Vec&lt;&lt;back::Backend as Backend&gt;::Fence&gt;,
  render_finished_semaphores: Vec&lt;&lt;back::Backend as Backend&gt;::Semaphore&gt;,
  image_available_semaphores: Vec&lt;&lt;back::Backend as Backend&gt;::Semaphore&gt;,
  command_buffers: Vec&lt;CommandBuffer&lt;back::Backend, Graphics, MultiShot, Primary&gt;&gt;,
  command_pool: ManuallyDrop&lt;CommandPool&lt;back::Backend, Graphics&gt;&gt;,
  framebuffers: Vec&lt;&lt;back::Backend as Backend&gt;::Framebuffer&gt;,
  image_views: Vec&lt;(&lt;back::Backend as Backend&gt;::ImageView)&gt;,
  render_pass: ManuallyDrop&lt;&lt;back::Backend as Backend&gt;::RenderPass&gt;,
  render_area: Rect,
  queue_group: QueueGroup&lt;back::Backend, Graphics&gt;,
  swapchain: ManuallyDrop&lt;&lt;back::Backend as Backend&gt;::Swapchain&gt;,
  device: ManuallyDrop&lt;back::Device&gt;,
  _adapter: Adapter&lt;back::Backend&gt;,
  _surface: &lt;back::Backend as Backend&gt;::Surface,
  _instance: ManuallyDrop&lt;back::Instance&gt;,
}
#}</code></pre></pre>
<p>And also make all the appropriate changes to the <code>Drop</code> impl, which you're smart
enough to do yourself at this point.</p>
<a class="header" href="#rendering-a-triangle" id="rendering-a-triangle"><h1>Rendering A Triangle</h1></a>
<p>Now that <code>HalState</code> supports it, actually rendering a triangle is pretty simple.
We just change our <code>do_the_render</code> function.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
fn do_the_render(hal_state: &amp;mut HalState, local_state: &amp;LocalState) -&gt; Result&lt;(), &amp;'static str&gt; {
  let x = ((local_state.mouse_x / local_state.frame_width) * 2.0) - 1.0;
  let y = ((local_state.mouse_y / local_state.frame_height) * 2.0) - 1.0;
  let triangle = Triangle {
    points: [[-0.5, 0.5], [-0.5, -0.5], [x as f32, y as f32]],
  };
  hal_state.draw_triangle_frame(triangle)
}
#}</code></pre></pre>
<p>Those coordinates are given in a 0.0 to 1.0 system, with +X going from left to
right, and +Y going from top to bottom. Two points of the triangle are fixed,
and the third one follows the mouse around as it moves. Looks like this:</p>
<p><img src="images/triangle-intro-complete.png" alt="triangle-intro-complete" /></p>
<p>You can find the full code file in the <code>examples/</code> directory of the repo.</p>
<a class="header" href="#shaders" id="shaders"><h1>Shaders</h1></a>
<p>I know you've been itching for a short lesson, so let's do a short lesson.</p>
<p>This time we're talking more about Shaders. <a href="https://www.youtube.com/watch?v=Kh0Y2hVe_bw">What are
shaders?</a> We just don't know.</p>
<a class="header" href="#glsl-and-spirv" id="glsl-and-spirv"><h1>GLSL and SPIRV</h1></a>
<p>Technically you can use any number of shader languages with <code>gfx-hal</code> as long as
they can compile to SPIRV. There's many options, and even an LLVM/SPIRV
converter (<a href="https://github.com/KhronosGroup/SPIRV-LLVM">really</a>), so you could
<em>potentially</em> use a very wide range of options.</p>
<p>For <strong>now</strong> now we're using a slightly special variant of GLSL, which stands for
&quot;open Graphics Library Shader Language&quot;, be cause it's technically the official
language for OpenGL, not Vulkan. Still, everyone already knew GLSL when Vulkan
came out, and it's actually quite good at the jobs, so they kept the text format
and just specified how to compile it to a new binary format.</p>
<p>The <code>shaderc-rs</code> crate that we're using compiles the textual GLSL into the
binary SPIRV for us. More precisely, the <code>shaderc-rs</code> crate's <code>build.rs</code> file
downloads the source of the <code>shaderc</code> C++ program and builds that, then puts
those binaries deep in your <code>target/</code> directory, then when you call the crate it
invokes that program to do the actual compilation. And it fails if the binaries
aren't there. Ahe crate itself doesn't know how to do any compilation at all.</p>
<p>If you think that sounds crazy, you're right. People are working on better
solutions, <a href="https://www.youtube.com/watch?v=yoy4_h7Pb3M">top men</a>, I assure you,
but until then this is the best system we've got.</p>
<p>Now there's a whole lot that can be said about GLSL. You can seriously write
<a href="https://thebookofshaders.com/">books</a> and <a href="http://www.iquilezles.org/">blogs</a>
and <a href="https://www.shadertoy.com/">demo site</a> after <a href="https://www.vertexshaderart.com/">demo
site</a> after <a href="http://glslsandbox.com/">demo
site</a> after <a href="https://www.interactiveshaderformat.com/">demo
site</a> for just GLSL. It's well out of
scope of this lesson or even this entire tutorial to try and cover it all.
Seriously you should read that book stuff and blog stuff and anything else you
can about GLSL if you really want to know it all.</p>
<p>What we're doing here is an <em>introduction</em> to the GLSL that we'll be using with
<code>gfx-hal</code> (which is basically normal GLSL, but with a few things you have to be
more clear about).</p>
<a class="header" href="#version" id="version"><h2>Version</h2></a>
<p>The first line of all your shaders will generally be</p>
<pre><code class="language-glsl">#version 450
</code></pre>
<p>There's technically a whole lot of GLSL versions, because each release of OpenGL
has a GLSL that goes with it, but since we're not <em>really</em> using OpenGL, we just
pretend we're using version 450 since that's what <code>shaderc</code> understands.</p>
<a class="header" href="#inputs-and-outputs" id="inputs-and-outputs"><h2>Inputs and Outputs</h2></a>
<p>Next you generally want to specify your inputs and outputs.</p>
<p>In normal GLSL you don't have to specify a layout value for each input and
output, but for the GLSL that we want to compile to SPIRV you are <em>required</em> to
give a layout location for each. The general format is</p>
<pre><code class="language-glsl">layout (location = INDEX) DIRECTION TYPE NAME;
</code></pre>
<ul>
<li>The <code>INDEX</code> values are just integer values. They're basically arbitrary, but
your Rust code and GLSL code must <strong>all</strong> agree on whatever you pick.
<ul>
<li>With a Vertex shader, the <code>AttributeDesc</code> determines the locations for
passing CPU side data into into GLSL data at the start of the process.</li>
<li>With a Fragment shader, the <code>SubpassDesc</code> determines the locations for
fragment outputs becoming framebuffer data at the end of the process.</li>
<li><em>Between</em> shaders the locations and variable outputs from one stage need to
match the locations and names of the next stage any time you want to pass
data between rendering stages.</li>
<li>There's a (rather small) limit on how many location slots you're allowed,
and if you use a struct type it can consume more than one slot. <a href="https://www.khronos.org/opengl/wiki/Layout_Qualifier_(GLSL)#Program_separation_linkage">The
Khronos
wiki</a>
has some more about the rules here if you want to know the exact details. I
don't expect any of our early lessons to hit these limits.</li>
</ul>
</li>
<li>The <code>DIRECTION</code> is a keyword: one of <code>in</code>, <code>out</code>, or <code>uniform</code>. Technically
there are other things you could put here but they're aliases for one of those
three so let's stick to the basics. An <code>in</code> value comes from a previous stage
(or the vertex buffer data, for the Vertex Shader), and an <code>out</code> value goes to
the next stage (or the framebuffer, for the Fragment Shader). A <code>uniform</code> is a
special kind of read-only value that we'll get to a little farther down the page.</li>
<li>The <code>TYPE</code> is a variable type, using C style names, so it's stuff like
<code>float</code>, <code>int</code>, and <code>uint</code>, not <code>f32</code>, <code>i32</code>, and <code>u32</code>. There's also <code>vecN</code>
where N is 2, 3, or 4 if you want a float vector, and you can have integer
vectors and such as well. You can even declare structs using the C style where
the block of fields is written <code>{ type1 field1; type2 field2; ... }</code>.</li>
<li>The <code>NAME</code> is just a name for the variable. Usually variable names are
camelCase with GLSL code that you find in the wild, but snake_case is fine too.</li>
</ul>
<p>In GLSL you'd normally have access to a few magical values that you can read and
write from, but not all of that translates cleanly with the <code>shaderc</code> compiler.
In our case, the thing that we need to be the most aware of is that instead of
writing to a magical and undeclared <code>gl_Position</code> value during the vertex shader
to determine a vertex's on-screen position, we need to declare and use a special
output like this:</p>
<pre><code class="language-glsl">layout (location = 0) out gl_PerVertex {
  vec4 gl_Position;
};
</code></pre>
<a class="header" href="#functions" id="functions"><h2>Functions</h2></a>
<p>Your GLSL can have any number of functions that you like, declared in the C
style where the output is on the left, then the function names and arguments.</p>
<p>At minimum each shader needs an &quot;entry point&quot;, as you may recall from the
pipeline declaration we did. By tradition it's just called <code>main</code>, and that's
probably good enough so we'll go with that in our shaders.</p>
<a class="header" href="#final-note" id="final-note"><h2>Final Note</h2></a>
<p>Just saying, in a normal project you'd probably want to have your shader code in
separate files, not directly as string constants. If you use a file extension
like .glsl, or maybe .vert and .frag, then your editor will probably have a mode
for syntax highlighting and other support for the GLSL format. That's a lot
better than a string literal. Somewhere in your Rust code you use the
<a href="https://doc.rust-lang.org/std/macro.include_str.html">include_str!</a> macro, like
this:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
static VERT_SRC: &amp;'static str = include_str!(&quot;dwarf.vert&quot;);
static FRAG_SRC: &amp;'static str = include_str!(&quot;dwarf.frag&quot;);
#}</code></pre></pre>
<p>And then that's how you'll have your shader source available.</p>
<p>Please understand that I'm using embedded string literals just because it's
easiest <em>for example purposes</em> to have each example be a single file at a time.</p>
<a class="header" href="#adding-a-vertex-attribute-for-color" id="adding-a-vertex-attribute-for-color"><h1>Adding A Vertex Attribute For Color</h1></a>
<p>So let's add a second attribute to our vertex data. We'll add an attribute for
color. Make a fancy rainbow triangle.</p>
<a class="header" href="#update-shader-code" id="update-shader-code"><h2>Update Shader Code</h2></a>
<p>First we update our shaders to use the new color attribute. A full color output
is of course RGBA (vec4), but as input we'll just give RGB and then let the
fragment shader add that A=1.0 in its output.</p>
<p>So our <em>input</em> locations are 0 (position) and 1 (color), and our <em>output</em>
locations are also 0 (the magical gl_Position) and 1 (frag_color for the
fragment shader). The fact that the position information is location 0 for both
inputs and outputs isn't special, you could swap it around if you wanted. Like
with the previous lesson, our fragment shader just promotes the 2D input into a
flat 3D output (which is actually a <code>vec4</code>, and I'll get to why that is in
the lesson on coordinate spaces).</p>
<p>The other line of <code>main</code>, saying <code>frag_color = color;</code> might look a little
silly, but there's a lot of magic wrapped up in that shorthand. It's <em>not</em> a
direct copy of the data, it's what makes that interpolation happen when more
than one fragment is generated by a vertex. If we wanted to have a direct copy
without interpolation we could specify the <code>flat</code> keyword on the output here
(eg: <code>layout (location = 1) flat out vec3 frag_color;</code>). In that case, each
fragment will use the vertex shader outputs of a particular vertex element (the
spec calls it the &quot;<a href="https://www.khronos.org/opengl/wiki/Primitive#Provoking_vertex">provoking
index</a>&quot;). Since
integer values can't be interpolated, you actually <em>must</em> specify <code>flat</code> with
integers that pass between shader stages.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub const VERTEX_SOURCE: &amp;str = &quot;#version 450
layout (location = 0) in vec2 position;
layout (location = 1) in vec3 color;

layout (location = 0) out gl_PerVertex {
  vec4 gl_Position;
};
layout (location = 1) out vec3 frag_color;

void main()
{
  gl_Position = vec4(position, 0.0, 1.0);
  frag_color = color;
}&quot;;
#}</code></pre></pre>
<p>For our fragment shader, we accept a single input, with the <em>exact same
location</em> as the output from the vertex shader. That's how the system knows to
make them match. (In some older GLSL versions you also could match up variables
by name, but SPIRV only goes by location.) This means that we actually don't
have a location 0 input for our fragment shader, and that's totally fine. Our
output is at location 0 (matching out <code>SubpassDesc</code>) vec4 (which is &quot;RGBA&quot;,
since it'll be treated as a color). We'll sensibly call it <code>color</code>. We just
promote the RGB color into an RGBA color by giving it an alpha of 1.0 (&quot;fully
opaque&quot;).</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub const FRAGMENT_SOURCE: &amp;str = &quot;#version 450
layout (location = 1) in vec3 frag_color;

layout (location = 0) out vec4 color;

void main()
{
  color = vec4(frag_color,1.0);
}&quot;;
#}</code></pre></pre>
<a class="header" href="#make-triangle-produce-the-new-data-format" id="make-triangle-produce-the-new-data-format"><h2>Make <code>Triangle</code> Produce The New Data Format</h2></a>
<p>Next we'll add a method to our <code>Triangle</code> type so that it can give us the
positions interleaved with some color data. We'll just have one corner be red,
one be green, and one blue.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub fn vertex_attributes(self) -&gt; [f32; 3 * (2 + 3)] {
    let [[a, b], [c, d], [e, f]] = self.points;
    [
      a, b, 1.0, 0.0, 0.0, // red
      c, d, 0.0, 1.0, 0.0, // green
      e, f, 0.0, 0.0, 1.0, // blue
    ]
  }
#}</code></pre></pre>
<a class="header" href="#create-a-pipeline-with-more-attributes" id="create-a-pipeline-with-more-attributes"><h2>Create A Pipeline With More Attributes</h2></a>
<p>Now we want to support the color attribute in our <code>create_pipeline</code> function.
That's pretty easy, we just change how the the <code>vertex_buffer</code> and <code>attributes</code>
values are defined.</p>
<ul>
<li><code>vertex_buffers</code> needs to have a bigger <code>stride</code> than before, because the
stride between elements is now &quot;five floats&quot; instead of the previous &quot;two
floats&quot;. We'll also cast the <code>usize</code> to the <code>ElemStride</code> type alias instead of
<code>u32</code>. It's the same type, but it lets future readers know that we probably
knew what we were doing (but only probably).</li>
<li><code>attributes</code> needs an entire second <code>AttributeDesc</code> entry to describe the
color data. The location is easy enough to understand, as is the binding. The
element format is now <code>Rgb32Float</code>, since this is three floats, and the offset
is the sum of the previous attributes up to this point.</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let vertex_buffers: Vec&lt;VertexBufferDesc&gt; = vec![VertexBufferDesc {
        binding: 0,
        stride: (size_of::&lt;f32&gt;() * 5) as ElemStride,
        rate: 0,
      }];
      let position_attribute = AttributeDesc {
        location: 0,
        binding: 0,
        element: Element {
          format: Format::Rg32Float,
          offset: 0,
        },
      };
      let color_attribute = AttributeDesc {
        location: 1,
        binding: 0,
        element: Element {
          format: Format::Rgb32Float,
          offset: (size_of::&lt;f32&gt;() * 2) as ElemOffset,
        },
      };
      let attributes: Vec&lt;AttributeDesc&gt; = vec![position_attribute, color_attribute];
#}</code></pre></pre>
<p>This setup, with <code>[(position, color), (position, color), ..]</code> is called
&quot;interleaved&quot; data. You can also have non-interleaved data by laying out all the
positions and then all the colors, and so on. Then you adjust your <code>stride</code> and
<code>offset</code> value to match that. We'll use interleaved data just because I
personally think it's easier to think about, and even the <a href="https://www.khronos.org/opengl/wiki/Vertex_Specification_Best_Practices#Formatting_VBO_Data">Khronos
wiki</a>
doesn't take a clear stance either way.</p>
<a class="header" href="#colors" id="colors"><h2>Colors!</h2></a>
<p>That's pretty much it. Didn't I promise that <em>eventually</em> it'd get easier to
enhance the program? That was pretty easy.</p>
<p>So easy... that we'll keep going and add a little bit more to the lesson.</p>
<a class="header" href="#push-constants" id="push-constants"><h1>Push Constants</h1></a>
<p>Last lesson I said that most of the time you don't re-upload vertex data every
frame. That's because usually you'd have a single model (an &quot;iconic triangle&quot;)
and then you'd tell the shader what animation frame, or position, or global
light level, or whatever else without touching the model data directly. It
doesn't seem like a big difference right now when there's only 3 vertex entries
in one triangle, but if there's <em>thousands</em> of vertex entries, and there's
<em>tens</em> of copies of that model that have to show up in the scene, well you'd
rather be doing all that math on your GPU (with dozens of ALUs) than on your CPU
(with only a handful of ALUs). That's like, the whole <em>point</em> of the GPU after
all.</p>
<p>So how do we know about these special global values during a draw call? They get
placed into things called <em>uniforms</em>, that's what the <code>uniform</code> keyword is for
in GLSL. When GLSL was used for OpenGL there were just &quot;uniforms&quot;, but with the
introduction of Vulkan now we've got both &quot;Uniform Buffers&quot; (like the old
uniforms) and also &quot;Push Constants&quot; (a fancy new thing). Uniforms get set before
a draw call and then they're a fixed, read-only value for that entire draw call.
No changes per-vertex or per-fragment or anything else. Any shader can access
that uniform, if it's been correctly configured in your pipeline setup.</p>
<p>As I said, push constants are newer, so older 3D books might not mention them if
you pick one up for some light technical reading, but they work the same way as
a uniform buffer. The biggest difference is that push constants can be assumed
to be significantly faster to update (because of where their physical memory is
on the GPU's card), and also they are somewhat easier to use (because there's no
faffing about with buffers), but you only get a <em>very</em> limited amount of push
constant space. With <code>gfx-hal</code> you can only use 128 <strong>bytes</strong> of push constant
space. The Vulkan spec assures that you have at least that much, and many
cards offer more these days, but currently <code>gfx-hal</code> has no way to ask the
graphics card exactly how much it supports. It's on the TODO list for 0.2.</p>
<p>As a demo of how to use push constants, we'll record a <code>std::time::Instant</code> at
the creation of our <code>HalState</code> and then use the time since that Instant to shift
our triangle towards black.</p>
<a class="header" href="#add-it-to-our-halstate" id="add-it-to-our-halstate"><h2>Add It To Our <code>HalState</code></h2></a>
<p>We first add an
<a href="https://doc.rust-lang.org/std/time/struct.Instant.html">Instant</a> to our
<code>HalState</code>.</p>
<p>Before we record the command buffer, we'll decide the current time value as an <code>f32</code>.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // DETERMINE THE TIME DATA
    let duration = Instant::now().duration_since(self.creation_instant);
    let time_f32 = duration.as_secs() as f32 + duration.subsec_nanos() as f32 * 1e-9;
#}</code></pre></pre>
<p>And just after we bind the vertex buffer, we also push the graphics constant:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
        encoder.bind_vertex_buffers(0, buffers);
        encoder.push_graphics_constants(&amp;self.pipeline_layout, ShaderStageFlags::FRAGMENT, 0, &amp;[time_f32.to_bits()]);
#}</code></pre></pre>
<p>The important part is that we have to remember to adjust our pipeline definition
as well. Remember how the <code>push_constants</code> value was an empty Vec? We need one
entry now (one push constant).</p>
<p>The format of the Vec is pretty easy: You give <code>(ShaderStageFlags, Range)</code>
tuples, with the ShaderStageFlags signifying what stage the push const will
appear in, and the Range specifying what range of that <code>push_graphics_constants</code>
slice we made will be accessed during that stage. Our stage is
<code>ShaderStageFlags::FRAGMENT</code>, and our range is to just use index 0 (which is
<code>0..1</code> in Rust's Range notation, don't forget).</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let push_constants = vec![(ShaderStageFlags::FRAGMENT, 0..1)];
      let layout = unsafe {
        device
          .create_pipeline_layout(&amp;descriptor_set_layouts, push_constants)
          .map_err(|_| &quot;Couldn't create a pipeline layout&quot;)?
      };
#}</code></pre></pre>
<a class="header" href="#add-it-to-the-shader-code" id="add-it-to-the-shader-code"><h2>Add It To The Shader Code</h2></a>
<p>Adding the push constants to a shader is pretty easy, but there are few rules.
All of your push constants appear in a single block with the special layout
value of <code>push_constant</code>. This block isn't <code>in</code> or <code>out</code>, instead it's
<code>uniform</code>. After that you give a name for the block type, the block itself, and then
the name that we're going to access it under. If you haven't programmed in C
before this, it may seem weird, but they think it's normal. We just have to go
with it.</p>
<p>Since we want a single <code>f32</code> to be the time, we define it as a block that holds
a single <code>float</code> value (the GLSL equivalent) which we call <code>time</code>. Then we
take <code>push.time</code> (think of it like they're all stored within a global <code>push</code>
struct), do some funny math on that so that it ends up as a 0.0 to 1.0 value
(since color channels are supposed to be in that range), and make a vec4. We can
multiply the vec4 from our time with the vec4 for our <code>frag_color</code>, and it does
a component-wise multiplication (a.x * b.x, a.y * b.y, etc). Then we shove the
result out the door. Bam, now our triangle shifts between black and rainbow.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub const FRAGMENT_SOURCE: &amp;str = &quot;#version 450
layout (push_constant) uniform PushConsts {
  float time;
} push;

layout (location = 1) in vec3 frag_color;

layout (location = 0) out vec4 color;

void main()
{
  float time01 = -0.9 * abs(sin(push.time * 0.9)) + 0.9;
  color = vec4(frag_color,1.0) * vec4(time01,time01,time01,1.0);
}&quot;;
#}</code></pre></pre>
<a class="header" href="#uniform-buffers" id="uniform-buffers"><h1>Uniform Buffers</h1></a>
<p>Like I said, there's a harsh limit on your push constant space. If you want more
global data than you can fit into your push constants you need to setup a
Uniform Buffer.</p>
<p>However, I also promised to keep this lesson short, and we'll be using uniform,
buffers for Textures during the next lesson, so we <em>won't</em> go into them right
now. Knowing about push constants already teaches you about the general idea of
uniform data, so we've covered enough to stop here.</p>
<a class="header" href="#textures" id="textures"><h1>Textures</h1></a>
<p>You can draw a lot with just triangles and colors. Do a search for &quot;low poly
art&quot; and you'll find a bunch of stuff that's just lots and lots of color shaded
triangles. Like the digital version of stained glass art. It's really cool.</p>
<p>But you can't make Skyrim or Smash Bros with just colored triangles. At some
point you want to stick a picture of a thing on those triangles. A picture that
you place onto a model is called a &quot;texture&quot;, even though really it's just a
normal image. In fact, you can use <code>gfx-hal</code> to render into an image, then keep
that image around and use it to texture your models.</p>
<p>A picture has &quot;pixels&quot;, and sometimes you'll hear about a texture having
&quot;texels&quot;. Just a way that some people distinguish between images intended for
final use and images intended for placement onto a model. The thing that's the
most special about textures is that since X, Y, and Z are already being used for
3D spatial positioning of a vertex, the position within a texture that it maps
to is called U and V. This is called <a href="https://en.wikipedia.org/wiki/UV_mapping">UV
Mapping</a> and it can get very
complicated if you have a single texture being wrapped around a 3D model.</p>
<p>As always, each stage of this is hard enough already, so we'll keep it simple.
This time out we're going to place a texture onto a &quot;Quad&quot; (two triangles
oriented to make a quadrilateral). Like before, part of the quad will follow the
mouse so that we can see it stretch around and even flip backwards when the
mouse moves &quot;behind&quot; the start of the quad.</p>
<p>What picture? Well I've drawn a pic of a friendly water pal in MS Paint, just
for this occasion. Here's a quarter-size sample:</p>
<p><img src="images/creature-smol.png" alt="creature-smol" /></p>
<a class="header" href="#making-a-quad" id="making-a-quad"><h1>Making A Quad</h1></a>
<p>So instead of having a <code>Triangle</code> type, we're going to have a <code>Quad</code> type. What
makes up a quad? Of course it's four points instead of three.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
#[derive(Debug, Clone, Copy)]
pub struct Quad {
  pub x: f32,
  pub y: f32,
  pub w: f32,
  pub h: f32,
}
#}</code></pre></pre>
<p>So if we have four &quot;real&quot; points, and we want to make two triangles... well we
need 3 points per triangle... We could just list out some of the points more
than once (scrub mode) or we could get fancy in how we tell the GPU to do it and
kick it up to a technique called &quot;Indexed Drawing&quot; (cool mode). The details of
that will be covered in a moment, right now we need to have a method to turn a
quad into some vertex data.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl Quad {
  pub fn vertex_attributes(self) -&gt; [f32; 4 * (2 + 3 + 2)] {
    let x = self.x;
    let y = self.y;
    let w = self.w;
    let h = self.h;
    #[cfg_attr(rustfmt, rustfmt_skip)]
    [
    // X    Y    R    G    B                  U    V
      x  , y+h, 1.0, 0.0, 0.0, /* red     */ 0.0, 1.0, /* bottom left */
      x  , y  , 0.0, 1.0, 0.0, /* green   */ 0.0, 0.0, /* top left */
      x+w, y  , 0.0, 0.0, 1.0, /* blue    */ 1.0, 0.0, /* bottom right */
      x+w, y+h, 1.0, 0.0, 1.0, /* magenta */ 1.0, 1.0, /* top right */
    ]
  }
}
#}</code></pre></pre>
<p>As you can see, we're approaching the limit of being able to specify it all as a
flat array. In future lessons we'll talk about having a proper Vertex type and
giving it fields so that it's easier to tell what parts are what and such. For a
single quad it's probably okay to do it like this.</p>
<p>So each vertex will have an XY position like before, and an RGB color like
before, and now we're adding a UV texture coordinate as well. We'll also have to
change around our pipeline setup to allow for the new vertex attribute.</p>
<p>Texture positions are always stored as 0.0 to 1.0 within the texture, U goes
horizontal (like X) and V is vertical (like Y). Within <code>gfx-hal</code>, the (0.0, 0.0)
position for UV coordinates is the <strong>top left corner</strong> of the image. Even if the
backend would normally use some other system, <code>gfx-hal</code> does the translations
necessary so that (0.0, 0.0) is the top left.</p>
<p>Note that some other graphics systems (mostly OpenGL) put the texture origin at
the <em>bottom</em> left instead! If you're trying out some shader code samples from
some other place and your images come out unexpectedly upside down, that's why.
You can compensate by flipping the image data before you upload it (I'll mention
that in a moment), or you can flip the computed coordinate before looking up the
data in the texture by using <code>1.0-V</code> instead of using <code>V</code> directly.</p>
<a class="header" href="#indexed-drawing" id="indexed-drawing"><h1>Indexed Drawing</h1></a>
<p>Indexed drawing is a way to save on vertex space by specifying the minimum
number of vertices in just any order within an array, and then also specifying
indexes into that array to describe the triangles themselves.</p>
<p>That might sound silly, at first. We save a little space on the vertex data that
we didn't specify twice, but then we have to give all the indexes, so are we
really saving much? Let's check.</p>
<p>Say we have 28 bytes per vertex (7 floats * 4 bytes each, that's what we have
right now), and also that indexes are given as <code>u16</code> values:</p>
<ul>
<li>If there's a Quad:
<ul>
<li>We reduce the vertex count from 6 to 4 (56 bytes saved)</li>
<li>We need to spend 6 indexes to describe the triangles (12 bytes used)</li>
<li>Net savings of 44 bytes per quad (56-12)</li>
</ul>
</li>
<li>If there's a Cube:
<ul>
<li>We reduce the vertex count from 36 to 8 (784 bytes saved)</li>
<li>We need to spend 36 indexes to describe the triangles (72 bytes used)</li>
<li>Net savings of 712 bytes per cube (784-72)</li>
</ul>
</li>
<li>As the model shape gets more complex, causing more triangles to share the same
vertex, the overall savings <em>improve</em>.</li>
</ul>
<p>So, yeah, that's totally sweet.</p>
<a class="header" href="#making-a-bufferbundle-type" id="making-a-bufferbundle-type"><h2>Making A <code>BufferBundle</code> Type</h2></a>
<p>First of all, now that we're having more than one buffer, we want to take that
buffer creation (declare buffer, check requirements, get memory, bind memory)
and pack it into its own thing. We'll call it a <code>BufferBundle</code>, because that
seems like a good enough name for a really generic sort of thing that we don't
even fully know how we'll use in the future.</p>
<p>The struct for it is very simple. We can even make it generic over the <code>Backend</code>
trait for maximum angle brackets in our code. (Rust is always better with more
angle brackets in the types, right?)</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct BufferBundle&lt;B: Backend, D: Device&lt;B&gt;&gt; {
  pub buffer: ManuallyDrop&lt;B::Buffer&gt;,
  pub requirements: Requirements,
  pub memory: ManuallyDrop&lt;B::Memory&gt;,
  pub phantom: PhantomData&lt;D&gt;,
}
#}</code></pre></pre>
<p>We'll make all the fields be <code>pub</code>, because (hot take) that's honestly the
better default for fields, unless you're trying to maintain some invariants with
the type. The <code>BufferBundle</code> isn't smart enough to have any invariants.</p>
<p>So we've got it generic over <code>Backend</code>, and then our methods will be using a
particular <code>Device</code>, and it'd be slightly insane to try and use a buffer between
two different device implementations, so we'll throw in a ðŸ‘»
<a href="https://doc.rust-lang.org/core/marker/struct.PhantomData.html">PhantomData</a> ðŸ‘»
so that things know we had a particular device in mind when we made the buffer.
Is there anything that PhantomData can't solve? I sure hope not. ðŸ‘»</p>
<p>Do we want this type to have any methods? Yeah, obviously, we want to be able to
make new ones. We'll just cut that code for making the vertex buffer and then
make it a little more buffer agnostic and reusable.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl&lt;B: Backend, D: Device&lt;B&gt;&gt; BufferBundle&lt;B, D&gt; {
  pub fn new(adapter: &amp;Adapter&lt;B&gt;, device: &amp;D, size: usize, usage: BufferUsage) -&gt; Result&lt;Self, &amp;'static str&gt; {
    unsafe {
      let mut buffer = device
        .create_buffer(size as u64, usage)
        .map_err(|_| &quot;Couldn't create a buffer!&quot;)?;
      let requirements = device.get_buffer_requirements(&amp;buffer);
      let memory_type_id = adapter
        .physical_device
        .memory_properties()
        .memory_types
        .iter()
        .enumerate()
        .find(|&amp;(id, memory_type)| {
          requirements.type_mask &amp; (1 &lt;&lt; id) != 0 &amp;&amp; memory_type.properties.contains(Properties::CPU_VISIBLE)
        })
        .map(|(id, _)| MemoryTypeId(id))
        .ok_or(&quot;Couldn't find a memory type to support the buffer!&quot;)?;
      let memory = device
        .allocate_memory(memory_type_id, requirements.size)
        .map_err(|_| &quot;Couldn't allocate buffer memory!&quot;)?;
      device
        .bind_buffer_memory(&amp;memory, 0, &amp;mut buffer)
        .map_err(|_| &quot;Couldn't bind the buffer memory!&quot;)?;
      Ok(Self {
        buffer: ManuallyDrop::new(buffer),
        requirements,
        memory: ManuallyDrop::new(memory),
        phantom: PhantomData,
      })
    }
  }
#}</code></pre></pre>
<p><strong>Note:</strong> In a program with many buffers you wouldn't want each buffer to be its
own memory allocation, because devices have a limit on the number of allocations
as well as on the total amount of allocated memory. However, implementing a
proper memory allocator is obviously way out of scope for right now, so we'll
just do the beginner thing.</p>
<p>Also we want to be able to throw them away when we're done. Question: Do we want
it to be <code>Drop</code>? Mmmm, no. But <code>HalState</code> is <code>Drop</code>, why not this too? Well,
<code>HalState</code> gets to be <code>Drop</code> because it's holding the <code>Device</code> field that's
needed to destroy all the other stuff it has. A <code>BufferBundle</code> has a PhantomData
for a device thing, but it isn't holding an <em>actual</em> <code>Device</code>, so it can't
perform a <code>Drop</code> on its own. <em>Should</em> it hold an actual device reference? I
think not. That'd make it really hard to store in our <code>HalState</code> alongside the
device field. The lifetimes would go crazy. So we'll just make a method to
<code>manually_drop</code> the type, and then it'll do the thing.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub unsafe fn manually_drop(&amp;self, device: &amp;D) {
    use core::ptr::read;
    device.destroy_buffer(ManuallyDrop::into_inner(read(&amp;self.buffer)));
    device.free_memory(ManuallyDrop::into_inner(read(&amp;self.memory)));
  }
}
#}</code></pre></pre>
<a class="header" href="#adding-bufferbundle-to-halstate" id="adding-bufferbundle-to-halstate"><h2>Adding <code>BufferBundle</code> To <code>HalState</code></h2></a>
<p>So now <code>HalState</code> wants two fields like this:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  vertices: BufferBundle&lt;back::Backend, back::Device&gt;,
  indexes: BufferBundle&lt;back::Backend, back::Device&gt;,
#}</code></pre></pre>
<p>Lokathor, why did we make BufferBundle be all generic and not have HalState be
all generic?</p>
<p>Because I tried that at first and doing the whole <code>HalState</code> generic gave me
some trouble at the time, so I just gave up on it. Obviously.</p>
<p>Creating these buffers is pretty easy:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    const F32_XY_RGB_UV_QUAD: usize = size_of::&lt;f32&gt;() * (2 + 3 + 2) * 4;
    let vertices = BufferBundle::new(&amp;adapter, &amp;device, F32_XY_RGB_UV_QUAD, BufferUsage::VERTEX)?;

    const U16_QUAD_INDICES: usize = size_of::&lt;u16&gt;() * 2 * 3;
    let indexes = BufferBundle::new(&amp;adapter, &amp;device, U16_QUAD_INDICES, BufferUsage::INDEX)?;
#}</code></pre></pre>
<p>And once we have an index buffer we can fill it up just once as part of our
<code>HalState</code> startup. Even if our quad changes from frame to frame, the indexes
don't, so we won't have to re-upload them each frame (the savings don't stop!)</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // Write the index data just once.
    unsafe {
      let mut data_target = device
        .acquire_mapping_writer(&amp;indexes.memory, 0..indexes.requirements.size)
        .map_err(|_| &quot;Failed to acquire an index buffer mapping writer!&quot;)?;
      const INDEX_DATA: &amp;[u16] = &amp;[0, 1, 2, 2, 3, 0];
      data_target[..INDEX_DATA.len()].copy_from_slice(&amp;INDEX_DATA);
      device
        .release_mapping_writer(data_target)
        .map_err(|_| &quot;Couldn't release the index buffer mapping writer!&quot;)?;
    }
#}</code></pre></pre>
<p>This is the exact same idea as writing to the vertex buffer, so it should look
very familiar. Do we want to make a <code>write_stuff</code> method on the <code>BufferBundle</code>
type and capture this pattern? Hmmmmmm, maybe later. I don't think it'd be hard,
but it's not really our goal right now.</p>
<a class="header" href="#performing-indexed-drawing" id="performing-indexed-drawing"><h2>Performing Indexed Drawing</h2></a>
<p>When we're doing our command buffer encoding we do it just a little different.</p>
<p>Now we have to bind an index buffer (there's <em>just one</em> index buffer per draw
call, even if there's more than one vertex buffer being combined)</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
        encoder.bind_index_buffer(IndexBufferView {
          buffer: &amp;self.indexes.buffer,
          offset: 0,
          index_type: IndexType::U16,
        });
#}</code></pre></pre>
<p>And then instead of calling <code>draw</code> with a vertex range, offset, and instance
range, we call <code>draw_indexed</code> with an index range, offset, and instance range.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
        encoder.draw_indexed(0..6, 0, 0..1);
#}</code></pre></pre>
<p>Like I said, it's only <em>slightly</em> different.</p>
<a class="header" href="#adding-a-vertex-attribute-for-texture-positions" id="adding-a-vertex-attribute-for-texture-positions"><h1>Adding A Vertex Attribute For Texture Positions</h1></a>
<p>This is just a quick little bit. Since we've got a new vertex attribute, we need
to update our pipeline to account for it.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      let vertex_buffers: Vec&lt;VertexBufferDesc&gt; = vec![VertexBufferDesc {
        binding: 0,
        stride: (size_of::&lt;f32&gt;() * (2 + 3 + 2)) as ElemStride,
        rate: 0,
      }];
      let position_attribute = AttributeDesc {
        location: 0,
        binding: 0,
        element: Element {
          format: Format::Rg32Float,
          offset: 0,
        },
      };
      let color_attribute = AttributeDesc {
        location: 1,
        binding: 0,
        element: Element {
          format: Format::Rgb32Float,
          offset: (size_of::&lt;f32&gt;() * 2) as ElemOffset,
        },
      };
      let uv_attribute = AttributeDesc {
        location: 2,
        binding: 0,
        element: Element {
          format: Format::Rg32Float,
          offset: (size_of::&lt;f32&gt;() * 5) as ElemOffset,
        },
      };
      let attributes: Vec&lt;AttributeDesc&gt; = vec![position_attribute, color_attribute, uv_attribute];
#}</code></pre></pre>
<p>Gosh, that's a very basic change. It's almost like <a href="https://docs.rs/glium/0.23.0/glium/macro.implement_vertex.html">a macro could do
it</a>. Naw, I'm
sure no one would ever <a href="https://docs.rs/vulkano/0.11.1/vulkano/macro.impl_vertex.html">use a macro for
that</a>. Never.</p>
<p>This is another reason why you want to switch to a proper &quot;vertex type&quot; as your
program grows bigger and bigger. It's not only easier to read, but you can start
throwing macros at your problems! We'll get there eventually.</p>
<a class="header" href="#loading-an-image" id="loading-an-image"><h1>Loading An Image</h1></a>
<p>I'm sorry ahead of time, but this process is a fiddly and long one compared to
how easy that index buffer thing is.</p>
<p>What we want is to take a collection of pixel data and get it form our CPU
memory into GPU memory. However, as much as you might think, &quot;oh that's super
common, that's gotta be like 1 call right?&quot; No, it's like 11 distinct steps,
some of which are several calls.</p>
<p>So, we'll make another type to hold this concept for us. This is very similar to
the BufferBundle, with some generics and PhantomData and such.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
pub struct LoadedImage&lt;B: Backend, D: Device&lt;B&gt;&gt; {
  pub image: ManuallyDrop&lt;B::Image&gt;,
  pub requirements: Requirements,
  pub memory: ManuallyDrop&lt;B::Memory&gt;,
  pub image_view: ManuallyDrop&lt;B::ImageView&gt;,
  pub sampler: ManuallyDrop&lt;B::Sampler&gt;,
  pub phantom: PhantomData&lt;D&gt;,
}
#}</code></pre></pre>
<p>And right now we can say that it's got a cleanup method too:</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
  pub unsafe fn manually_drop(&amp;self, device: &amp;D) {
    use core::ptr::read;
    device.destroy_sampler(ManuallyDrop::into_inner(read(&amp;self.sampler)));
    device.destroy_image_view(ManuallyDrop::into_inner(read(&amp;self.image_view)));
    device.destroy_image(ManuallyDrop::into_inner(read(&amp;self.image)));
    device.free_memory(ManuallyDrop::into_inner(read(&amp;self.memory)));
  }
#}</code></pre></pre>
<p>And it's got a load method which is complex enough that we'll talk about it in
steps.</p>
<a class="header" href="#method-signature" id="method-signature"><h2>Method Signature</h2></a>
<p>What will we need? Well, we need and Adapter and Device like we do for a lot of
these memory things, but we'll also be telling the GPU to do stuff, so we'll
need a CommandPool and a CommandQueue. They get bound by <code>Capability + Supports&lt;Transfer&gt;</code>, in other words, they have to be pools that support the
ability to transfer things around. That's actually <em>all</em> possible pools and
queues (since graphics and compute both also support transfer), but it doesn't
really hurt to be clear what we're looking for. Lastly we need the image to be
uploading. We'll use the <a href="https://docs.rs/image">image</a> crate because it's the
most commonly used one. They support most of the file formats and pixel types
you'd need.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
impl&lt;B: Backend, D: Device&lt;B&gt;&gt; LoadedImage&lt;B, D&gt; {
  pub fn new&lt;C: Capability + Supports&lt;Transfer&gt;&gt;(
    adapter: &amp;Adapter&lt;B&gt;, device: &amp;D, command_pool: &amp;mut CommandPool&lt;B, C&gt;,
    command_queue: &amp;mut CommandQueue&lt;B, C&gt;, img: image::RgbaImage,
  ) -&gt; Result&lt;Self, &amp;'static str&gt; {
    unsafe {
#}</code></pre></pre>
<a class="header" href="#figure-out-some-memory-stuff" id="figure-out-some-memory-stuff"><h2>Figure Out Some Memory Stuff.</h2></a>
<p>First, before we actually do any GPU interaction, we need to double check on
some values we'll be using. See, we're going to make a buffer for this whole
upload process, as you might guess. However, unlike with vertex data, the
backend is allowed to be more picky about the memory alignment of image data. We
have to have the individual values aligned properly (eg: <code>u32</code> aligned to 4
bytes), but we <em>also</em> have to have the rows of the image aligned to their own
alignment.</p>
<p>Some image memory needs a little extra padding between rows to be optimal. The
Adapter has a field for the physical device, and that has a method to get the
limits. Those limits include a <code>min_buffer_copy_pitch_alignment</code> field, which is
a fairly poor name perhaps, but it means how well aligned the entire row of of
pixels in an image have to be. For example, we might need to align each row into
a 4 unit wide buffer, so if we have some little picture that's 50x50 we'd need
to place it into a buffer that's actually 52 pixels wide to match the alignment.</p>
<p>We take the <code>min_buffer_copy_pitch_alignment</code> and do a little math to basically
&quot;round up&quot; our starting row size to the next aligned value. This will give us a
row &quot;pitch&quot; value for the buffer that will always be equal to or greater than
the image's size in our CPU memory.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 0. First we compute some memory related values.
      let pixel_size = size_of::&lt;image::Rgba&lt;u8&gt;&gt;();
      let row_size = pixel_size * (img.width() as usize);
      let limits = adapter.physical_device.limits();
      let row_alignment_mask = limits.min_buffer_copy_pitch_alignment as u32 - 1;
      let row_pitch = ((row_size as u32 + row_alignment_mask) &amp; !row_alignment_mask) as usize;
      debug_assert!(row_pitch as usize &gt;= row_size);
#}</code></pre></pre>
<p>Okay, now we're ready to focus on the actual upload process.</p>
<a class="header" href="#make-a-staging-buffer" id="make-a-staging-buffer"><h2>Make A Staging Buffer</h2></a>
<p>In the past we've been able to map memory which we can directly write into our
buffers (the Vertex Buffer and Index Buffer). This is because we've been using
<code>CPU_VISIBLE</code> memory, which for most Vulkan vendors means the memory being used
is in CPU RAM, not in VRAM which is on the graphics card. If we used this for an
image, sampling that image (aka &quot;reading it&quot;) would be very, <em>very</em> slow.
Instead, what we want to do is make an image that uses a different type of
memory called <code>DEVICE_LOCAL</code> (that is, &quot;local to the graphics device&quot;). It's RAM
that's actually on the graphics card itself, much faster for the GPU to use.
However, being close to the GPU means it's far from us (we're the CPU). It's so
far that you actually can't even get there from here. We have to make a &quot;staging
buffer&quot;, copy our image from CPU memory into that, then tell the GPU to copy
from the staging buffer into the actual image memory. Yes, really.</p>
<p>For the staging buffer we can use the <code>BufferBundle</code> type, and we want the usage
to be &quot;transfer source&quot;.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 1. make a staging buffer with enough memory for the image, and a
      //    transfer_src usage
      let required_bytes = row_pitch * img.height() as usize;
      let staging_bundle =
        BufferBundle::new(&amp;adapter, device, required_bytes, BufferUsage::TRANSFER_SRC)?;
#}</code></pre></pre>
<a class="header" href="#write-to-the-staging-buffer" id="write-to-the-staging-buffer"><h2>Write To The Staging Buffer</h2></a>
<p>Now that our staging buffer is created, we can &quot;stage&quot; the data into it.</p>
<p>Except, remember that alignment issue? <em>Sometimes</em> the buffer will have a pitch
that's exactly as big as our image's width, and sometimes it will have a bigger
pitch. So we can't do a straight copy like we've done in the past. We have to do
a row-wise copy.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 2. use mapping writer to put the image data into that buffer
      let mut writer = device
        .acquire_mapping_writer::&lt;u8&gt;(&amp;staging_bundle.memory, 0..staging_bundle.requirements.size)
        .map_err(|_| &quot;Couldn't acquire a mapping writer to the staging buffer!&quot;)?;
      for y in 0..img.height() as usize {
        let row = &amp;(*img)[y * row_size..(y + 1) * row_size];
        let dest_base = y * row_pitch;
        writer[dest_base..dest_base + row.len()].copy_from_slice(row);
      }
      device
        .release_mapping_writer(writer)
        .map_err(|_| &quot;Couldn't release the mapping writer to the staging buffer!&quot;)?;
#}</code></pre></pre>
<p>See that part where we iterate the picture rows and the writer rows in the
<em>same</em> direction? If we needed to flip our image data around we'd iterate one of
them in the <em>opposite</em> direction (doesn't matter which) and then our image would
get uploaded with a vertical flip applied.</p>
<a class="header" href="#make-an-image" id="make-an-image"><h2>Make An Image</h2></a>
<p>Now we make an Image on the Device with
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/device/trait.Device.html#tymethod.create_image">create_image</a>.
This is just a description of what the image will be like. Like with Buffers, an
Image doesn't automatically have any memory bound to it.</p>
<ul>
<li><code>kind</code> looks like just the dimensionality of the image, but it's <a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/VkImageViewCreateInfo.html">actually
complex enough to need a huge
table</a>
of what's allowed to go with what.</li>
<li><code>mip_levels</code> is for when you do mip mapping to have more than one level of
detail for the image. We won't do that yet, so just leave it at 1.</li>
<li><code>format</code> is the pixel format of the image. This might not match the pixel
format of the swapchain that the image gets used with, and then the GPU will
convert around and stuff. Thankfully our formats will probably match here.</li>
<li><code>tiling</code> affects the memory layout of the image. In this case the image will
be purely used within the GPU, so we'll pick <code>Optimal</code> and let the GPU be
happy.</li>
<li><code>usage</code> is an image usage (which is <em>similar to but not the same as</em> the
buffer usage flags), and here we want <code>TRANSFER_DST</code> (since it will be the
destination for our staging buffer transfer) and also <code>SAMPLED</code> (since the
fragment shader will sample from it).</li>
<li><code>view_caps</code> is if we want our view into the image to support anything special,
but we don't need any of that.</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 3. Make an image with transfer_dst and SAMPLED usage
      let mut the_image = device
        .create_image(
          gfx_hal::image::Kind::D2(img.width(), img.height(), 1, 1),
          1,
          Format::Rgba8Srgb,
          gfx_hal::image::Tiling::Optimal,
          gfx_hal::image::Usage::TRANSFER_DST | gfx_hal::image::Usage::SAMPLED,
          gfx_hal::image::ViewCapabilities::empty(),
        )
        .map_err(|_| &quot;Couldn't create the image!&quot;)?;
#}</code></pre></pre>
<a class="header" href="#allocate-some-image-memory" id="allocate-some-image-memory"><h2>Allocate Some Image Memory</h2></a>
<p>Next we want to allocate some memory for the image and bind it to the image.
This works <em>very close</em> to how it works with the <code>BufferBundle</code> type. However,
remember that instead of memory that's <code>CPU_VISIBLE</code>, we want memory that's
<code>DEVICE_LOCAL</code>.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 4. allocate memory for the image and bind it
      let requirements = device.get_image_requirements(&amp;the_image);
      let memory_type_id = adapter
        .physical_device
        .memory_properties()
        .memory_types
        .iter()
        .enumerate()
        .find(|&amp;(id, memory_type)| {
          // BIG NOTE: THIS IS DEVICE LOCAL NOT CPU VISIBLE
          requirements.type_mask &amp; (1 &lt;&lt; id) != 0
            &amp;&amp; memory_type.properties.contains(Properties::DEVICE_LOCAL)
        })
        .map(|(id, _)| MemoryTypeId(id))
        .ok_or(&quot;Couldn't find a memory type to support the image!&quot;)?;
      let memory = device
        .allocate_memory(memory_type_id, requirements.size)
        .map_err(|_| &quot;Couldn't allocate image memory!&quot;)?;
      device
        .bind_image_memory(&amp;memory, 0, &amp;mut the_image)
        .map_err(|_| &quot;Couldn't bind the image memory!&quot;)?;
#}</code></pre></pre>
<p>The same note applies here as with the <code>BufferBundle</code>: in a program with many
textures you'd need to grab a big block of memory and use a sub-allocator to
pick out actual image memory yourself because there's a limit on total
allocations among GPU memory. This is fine for now though.</p>
<a class="header" href="#create-an-imageview-and-sampler" id="create-an-imageview-and-sampler"><h2>Create An <code>ImageView</code> And <code>Sampler</code></h2></a>
<p>We don't use it immediately, but later on we'll need to have both an <code>ImageView</code>
and <code>Sampler</code> for our Image, so we'll make them right now and store them in the
<code>LoadedImage</code> struct. Conceptually, the LoadedImage would just be somewhat
incomplete without them.</p>
<p>In <code>gfx-hal</code>, there are basically three &quot;levels&quot; of both image and buffer
resources. First there's the <code>Memory</code>, which is a handle to a specific piece of
device memory, which is where the raw data for that resource is stored. Then
there's the <code>Buffer</code> or <code>Image</code>, which is information about the size, planned
usage, and any special properties of the resource contained in the backing
memory. Finally there is the resource view. In this case, that's an <code>ImageView</code>,
but there are also <code>BufferView</code>s that we just haven't used yet. The view is like
a window into a resource, it describes how to think of it (the type of data,
pixel format, etc) and which part of the resource to view. You're even allowed
to have more than one view into the same resource, if you want.</p>
<p>On top of the <code>ImageView</code> layer we also want to use what is called a <code>Sampler</code>.
This is what lets us use the image data within a shader. In a graphics program
you usually don't want the direct value of a specific pixel in a texture,
instead you want to get the color of a texture at some <em>relative</em> point,
probably &quot;between&quot; two pixels. What <em>exactly</em> does that mean? The <code>Sampler</code>
decides what it means.</p>
<p>The sampler describes how we want the shader to interpolate between the colors
of a texture, including how to &quot;zoom&quot; the image to be bigger or smaller if it's
being stretched across a space that doesn't match the original image size.
Samplers are created and used in a similar way to other device resources. The
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/image/struct.SamplerInfo.html#method.new">SamplerInfo::new</a>
method can do the work here, because using defaults for most of the stuff is
fine.</p>
<ul>
<li>We pick a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/image/enum.Filter.html">Filter</a>, which
determines how to pick the color that's at a &quot;sub-pixel&quot; location. <code>Nearest</code>
picks all color from just one pixel, whichever pixel the point would be at if
you rounded the floating point position into an integer position. This gives
results that are usually sharp and blocky. There's also <code>Linear</code> which does a
color blend between the pixels around the fractional location, weighted by how
far the location is towards each side. So if 2 is green and 3 is white, pixel
2.9 is 90% white and 10% green. The blend happens in however many dimensions
the image has, so a 1D image is a linear blend, a 2D image is a &quot;bilinear&quot;
blend, and so on. This gives results that are smoother looking.</li>
<li>We also pick a
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/image/enum.WrapMode.html">WrapMode</a>.
Texture coordinates are in the 0.0 to 1.0 range, and if you access something
outside of that it's not actually an error like accessing outside a slice
bound is. Instead, the <code>WrapMode</code> determines how the out of bounds location is
translated to be back in bounds.</li>
</ul>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 5. create image view and sampler
      let image_view = device
        .create_image_view(
          &amp;the_image,
          gfx_hal::image::ViewKind::D2,
          Format::Rgba8Srgb,
          gfx_hal::format::Swizzle::NO,
          SubresourceRange {
            aspects: Aspects::COLOR,
            levels: 0..1,
            layers: 0..1,
          },
        )
        .map_err(|_| &quot;Couldn't create the image view!&quot;)?;
      let sampler = device
        .create_sampler(gfx_hal::image::SamplerInfo::new(
          gfx_hal::image::Filter::Nearest,
          gfx_hal::image::WrapMode::Tile,
        ))
        .map_err(|_| &quot;Couldn't create the sampler!&quot;)?;
#}</code></pre></pre>
<a class="header" href="#create-a-commandbuffer" id="create-a-commandbuffer"><h2>Create A <code>CommandBuffer</code></h2></a>
<p>We've done this step before, it's not weird. The biggest difference is that now
we're making a <code>OneShot</code> command buffer. Those other command buffers that we use
over and over are <code>MultiShot</code>. They both implement
<a href="https://docs.rs/gfx-hal/0.1.0/gfx_hal/command/trait.Shot.html">Shot</a>. It's
basically what it sounds like, one can be reused and one can't. At the end of
the loading process we'll be throwing this shot away
(<a href="https://www.youtube.com/watch?v=Ic7NqP_YGlg">Hamilton</a> would be so upset),
that means we'll make a <code>OneShot</code> buffer this time around.</p>
<p><code>OneShot</code> buffers are actually less restrictive than <code>MultiShot</code> buffers, but
the graphics driver can sometimes make some optimizations based on the manner in
which you plan to use the buffer. If you really need to care about it, the exact
details of what type of buffer to use when, with what video cards, with what
drivers, it's all one of those &quot;you have to profile it to know for sure&quot;
problems. We're not trying to push out that much performance yet though.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 6. create a command buffer
      let mut cmd_buffer = command_pool.acquire_command_buffer::&lt;gfx_hal::command::OneShot&gt;();
      cmd_buffer.begin();
#}</code></pre></pre>
<a class="header" href="#first-pipeline-barrier" id="first-pipeline-barrier"><h2>First Pipeline Barrier</h2></a>
<p>The image memory starts with undefined values (much like memory on the CPU) but
it <em>also</em> starts with an undefined <em>layout</em>. Which sounds a little weird, but
it's totally a thing.</p>
<p>Our first command into the buffer is to transition the image memory into a new
layout that's the best possible layout for being a transfer destination. What
<em>exactly</em> that means is up to the GPU, but it knows what to do.</p>
<p>In addition, we transfer the <code>Access</code> type from none at all to <code>TRANSFER_WRITE</code>,
which tells the GPU the type of access which we are going to be performing on
this resource for now. It's important that we transition resources which we want
to use in specific ways to the proper Layout and Access type, because performing
operations which are not supported by the Layout/Access that a resource
currently has isn't just a speed penalty, it's an explicit error and possibly
even <strong>Undefined Behavior</strong> (oh no!). <code>gfx-hal</code> goes to a lot of trouble to make
sure that all the backends behave like Vulkan even if they're not Vulkan, so you
can use the Vulkan spec to know which operations are supported by each
<a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/VkImageLayout.html">Layout</a>
and
<a href="https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/VkAccessFlagBits.html">Access</a>
type.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 7. Use a pipeline barrier to transition the image from empty/undefined
      //    to TRANSFER_WRITE/TransferDstOptimal
      let image_barrier = gfx_hal::memory::Barrier::Image {
        states: (gfx_hal::image::Access::empty(), Layout::Undefined)
          ..(
            gfx_hal::image::Access::TRANSFER_WRITE,
            Layout::TransferDstOptimal,
          ),
        target: &amp;the_image,
        families: None,
        range: SubresourceRange {
          aspects: Aspects::COLOR,
          levels: 0..1,
          layers: 0..1,
        },
      };
      cmd_buffer.pipeline_barrier(
        PipelineStage::TOP_OF_PIPE..PipelineStage::TRANSFER,
        gfx_hal::memory::Dependencies::empty(),
        &amp;[image_barrier],
      );
#}</code></pre></pre>
<a class="header" href="#do-the-copy" id="do-the-copy"><h2>Do The Copy</h2></a>
<p>Our next command is to actually do that copy from the staging buffer (in
<code>CPU_VISIBLE</code> memory) into the image (the <code>DEVICE_LOCAL</code> memory).</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 8. perform copy from staging buffer to image
      cmd_buffer.copy_buffer_to_image(
        &amp;staging_bundle.buffer,
        &amp;the_image,
        Layout::TransferDstOptimal,
        &amp;[gfx_hal::command::BufferImageCopy {
          buffer_offset: 0,
          buffer_width: (row_pitch / pixel_size) as u32,
          buffer_height: img.height(),
          image_layers: gfx_hal::image::SubresourceLayers {
            aspects: Aspects::COLOR,
            level: 0,
            layers: 0..1,
          },
          image_offset: gfx_hal::image::Offset { x: 0, y: 0, z: 0 },
          image_extent: gfx_hal::image::Extent {
            width: img.width(),
            height: img.height(),
            depth: 1,
          },
        }],
      );
#}</code></pre></pre>
<a class="header" href="#transition-the-image-into-shader-friendly-layout" id="transition-the-image-into-shader-friendly-layout"><h2>Transition The Image Into Shader-Friendly Layout</h2></a>
<p>Just like there's a layout for being an optimal destination, there's also a
layout for being an optimal place for a shader to read from, and an access type
for being read from a shader. We've gotta issue a pipeline barrier for this
transition too. There are other ways to transition resources which should be
used instead of pipeline barriers when possible (specifically, between render
Subpasses), but in this case pipeline barriers are required (as always, &quot;more on
that in future lessons&quot;).</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 9. use pipeline barrier to transition the image to SHADER_READ access/
      //    ShaderReadOnlyOptimal layout
      let image_barrier = gfx_hal::memory::Barrier::Image {
        states: (
          gfx_hal::image::Access::TRANSFER_WRITE,
          Layout::TransferDstOptimal,
        )
          ..(
            gfx_hal::image::Access::SHADER_READ,
            Layout::ShaderReadOnlyOptimal,
          ),
        target: &amp;the_image,
        families: None,
        range: SubresourceRange {
          aspects: Aspects::COLOR,
          levels: 0..1,
          layers: 0..1,
        },
      };
      cmd_buffer.pipeline_barrier(
        PipelineStage::TRANSFER..PipelineStage::FRAGMENT_SHADER,
        gfx_hal::memory::Dependencies::empty(),
        &amp;[image_barrier],
      );
#}</code></pre></pre>
<a class="header" href="#submit-that-buffer" id="submit-that-buffer"><h2>Submit That Buffer!</h2></a>
<p>With all our commands written we submit the buffer. Except we don't have a fence
for the GPU to signal us when the whole thing is done. Well, it's not like we're
uploading whole images every frame, so we'll just make a temporary fence and
then destroy it after.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 10. Submit the cmd buffer to queue and wait for it
      cmd_buffer.finish();
      let upload_fence = device
        .create_fence(false)
        .map_err(|_| &quot;Couldn't create an upload fence!&quot;)?;
      command_queue.submit_nosemaphores(Some(&amp;cmd_buffer), Some(&amp;upload_fence));
      device
        .wait_for_fence(&amp;upload_fence, core::u64::MAX)
        .map_err(|_| &quot;Couldn't wait for the fence!&quot;)?;
      device.destroy_fence(upload_fence);
#}</code></pre></pre>
<a class="header" href="#destroy-the-other-temporary-resources" id="destroy-the-other-temporary-resources"><h2>Destroy The Other Temporary Resources</h2></a>
<p>We're all done, but we can't forget to clean up that staging buffer, and also
free that <code>OneShot</code> command buffer.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 11. Destroy the staging bundle and one shot buffer now that we're done
      staging_bundle.manually_drop(device);
      command_pool.free(Some(cmd_buffer));
#}</code></pre></pre>
<a class="header" href="#success" id="success"><h2>Success!</h2></a>
<p>We've finally uploaded an image!</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      Ok(Self {
        image: ManuallyDrop::new(the_image),
        requirements,
        memory: ManuallyDrop::new(memory),
        image_view: ManuallyDrop::new(image_view),
        sampler: ManuallyDrop::new(sampler),
        phantom: PhantomData,
      })
#}</code></pre></pre>
<a class="header" href="#shading-the-image-onto-the-quad" id="shading-the-image-onto-the-quad"><h1>Shading The Image Onto The Quad</h1></a>
<p>To actually use this image we've got more work ahead of us. Of course, that dumb
graphics pipeline of ours has to change yet again to accommodate this new thing.
So we'll have to make some changes to <code>create_pipeline</code>.</p>
<a class="header" href="#descriptorsetlayout" id="descriptorsetlayout"><h2>DescriptorSetLayout</h2></a>
<p>First we need a <code>DescriptorSetLayout</code>, which is a backend specific definition of
the <em>layout</em> of the resources in the graphics pipeline process. Later we'll bind
those as <code>Descriptors</code>, which we can access in the shader.</p>
<p>To be clear: we are not yet binding the actual resources which we want to use,
only describing the kind and place in which those resources will have to go. As
you'll see later, as long as we follow this layout, we can bind multiple
different resources into the same slots. We need a <code>SampledImage</code> and a
<code>Sampler</code>. Like with other shader stuff, the <code>binding</code> value here has to match
the number that the GLSL code will use.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 1. you make a DescriptorSetLayout which is the layout of one descriptor
      //    set
      let descriptor_set_layouts: Vec&lt;&lt;back::Backend as Backend&gt;::DescriptorSetLayout&gt; =
        vec![unsafe {
          device
            .create_descriptor_set_layout(
              &amp;[
                DescriptorSetLayoutBinding {
                  binding: 0,
                  ty: gfx_hal::pso::DescriptorType::SampledImage,
                  count: 1,
                  stage_flags: ShaderStageFlags::FRAGMENT,
                  immutable_samplers: false,
                },
                DescriptorSetLayoutBinding {
                  binding: 1,
                  ty: gfx_hal::pso::DescriptorType::Sampler,
                  count: 1,
                  stage_flags: ShaderStageFlags::FRAGMENT,
                  immutable_samplers: false,
                },
              ],
              &amp;[],
            )
            .map_err(|_| &quot;Couldn't make a DescriptorSetLayout&quot;)?
        }];
#}</code></pre></pre>
<a class="header" href="#descriptorpool" id="descriptorpool"><h2>DescriptorPool</h2></a>
<p>Next we need a <a href="DescriptorPool">DescriptorPool</a>. This comes from our <code>Device</code>,
and allows us to actually allocate some <code>Descriptor</code> and <code>DescriptorSet</code> values.
Unlike with the CommandPool, we have to decide how much of each kind of
descriptor, as well as how many sets, we'll <em>ever</em> allocate out of this thing
ahead of time.</p>
<p>The number of Descriptors is shared between all descriptor sets. We only want
one SampledImage and one Sampler, both in a single set.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 2. you create a descriptor pool, and when making that descriptor pool
      //    you specify how many sets you want to be able to allocate from the
      //    pool, as well as the maximum number of each kind of descriptor you
      //    want to be able to allocate from that pool, total, for all sets.
      let mut descriptor_pool = unsafe {
        device
          .create_descriptor_pool(
            1, // sets
            &amp;[
              gfx_hal::pso::DescriptorRangeDesc {
                ty: gfx_hal::pso::DescriptorType::SampledImage,
                count: 1,
              },
              gfx_hal::pso::DescriptorRangeDesc {
                ty: gfx_hal::pso::DescriptorType::Sampler,
                count: 1,
              },
            ],
          )
          .map_err(|_| &quot;Couldn't create a descriptor pool!&quot;)?
      };
#}</code></pre></pre>
<p>Technically you could do either steps 1 or 2 first, as long as they're both done
before step 3.</p>
<a class="header" href="#allocate-a-descriptorset" id="allocate-a-descriptorset"><h2>Allocate A DescriptorSet</h2></a>
<p>With a layout and a pool, we're ready to actually allocate a <code>DescriptorSet</code>. A
DescriptorSet is a set of descriptors in some specific layout. When it's first
created, there <em>still</em> aren't actual Descriptors written into the set yet, so
that's the next thing we'll have to do.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
      // 3. you allocate said descriptor set from the pool you made earlier
      let descriptor_set = unsafe {
        descriptor_pool
          .allocate_set(&amp;descriptor_set_layouts[0])
          .map_err(|_| &quot;Couldn't make a Descriptor Set!&quot;)?
      };
#}</code></pre></pre>
<a class="header" href="#create-the-descriptors-you-want-to-write" id="create-the-descriptors-you-want-to-write"><h2>Create The Descriptors You Want To Write</h2></a>
<p>At this point you'd make the actual descriptors you'd want to write. For us
that's the ImageView and the Sampler that are part of our <code>LoadedImage</code>. So, in
the <code>HalState</code> startup we'll load up the image after we call <code>create_pipeline</code>.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // 4. You create the actual descriptors which you want to write into the
    //    allocated descriptor set (in this case an image and a sampler)
    let texture = LoadedImage::new(
      &amp;adapter,
      &amp;device,
      &amp;mut command_pool,
      &amp;mut queue_group.queues[0],
      image::load_from_memory(CREATURE_BYTES)
        .expect(&quot;Binary corrupted!&quot;)
        .to_rgba(),
    )?;
#}</code></pre></pre>
<p>This could technically be either before or after the call to <code>create_pipeline</code>
(since neither depends on the other), but since it's &quot;step 4&quot; in this process,
and <code>create_pipeline</code> had steps 1 through 3, we'll put it after
<code>create_pipeline</code>.</p>
<a class="header" href="#write-the-descriptors-into-the-descriptorset" id="write-the-descriptors-into-the-descriptorset"><h2>Write The Descriptors Into The DescriptorSet</h2></a>
<p>Once all the resources which will be bound as <code>Descriptors</code> and the
<code>DescriptorSet</code> exist at the same time (after <code>create_pipeline</code> and after we
have our <code>LoadedImage</code>), we can write the one into the other. This binds the
specific ImageView (being used as a SampledImage descriptor) and Sampler (being
used as a Sampler descriptor) to that specific DescriptorSet.</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
    // 5. You write the descriptors into the descriptor set using
    //    write_descriptor_sets which you pass a set of DescriptorSetWrites
    //    which each write in one or more descriptors to the set
    unsafe {
      device.write_descriptor_sets(vec![
        gfx_hal::pso::DescriptorSetWrite {
          set: &amp;descriptor_set,
          binding: 0,
          array_offset: 0,
          descriptors: Some(gfx_hal::pso::Descriptor::Image(
            texture.image_view.deref(),
            Layout::Undefined,
          )),
        },
        gfx_hal::pso::DescriptorSetWrite {
          set: &amp;descriptor_set,
          binding: 1,
          array_offset: 0,
          descriptors: Some(gfx_hal::pso::Descriptor::Sampler(texture.sampler.deref())),
        },
      ]);
    }
#}</code></pre></pre>
<a class="header" href="#bind-the-descriptor-set-during-render-pass-encoding" id="bind-the-descriptor-set-during-render-pass-encoding"><h2>Bind The Descriptor Set During Render Pass Encoding</h2></a>
<p>Lastly, when we're doing all of our binding for the render pass, we have to bind
this stuff too. If you had multiple images which you wanted to bind into the
same shader program at different times, you'd create multiple DescriptorSets and
then write the different resources into those different DescriptorSets and then
finally bind the correct set before each draw call. You can also bind more than
one set into a single draw call, but the uses for that are a bit more
complicated (&quot;for another lesson&quot;).</p>
<pre><pre class="playpen"><code class="language-rust">
# #![allow(unused_variables)]
#fn main() {
        // 6. You actually bind the descriptor set in the command buffer before
        //    the draw call using bind_graphics_descriptor_sets
        encoder.bind_graphics_descriptor_sets(
          &amp;self.pipeline_layout,
          0,
          Some(self.descriptor_set.deref()),
          &amp;[],
        );
#}</code></pre></pre>
<p>Note 1: We've got it a in few places, but that <code>deref</code> call there is to make the
<code>Deref</code> trait on the <code>ManuallyDrop</code> wrapper trigger, because just using <code>&amp;</code>
doesn't do it. probably because <code>bind_graphics_descriptor_sets</code> is so generic
that <code>rustc</code> actually gets confused about what we're even trying to say.</p>
<p>Note 2: here we're using <code>Some(thing)</code> instead of making another <code>ArrayVec</code> of
length 1. I think we already did it above in this lesson too. It's ultimately
the same effect (since the generic here is for <code>IntoIterator</code>), and arguably
easier to use this way. However, I wanted to make sure that you knew how to do
the <code>ArrayVec</code> version, so it got shown off first. Using <code>Some(thing)</code> is quick
and easy, but it locks you at one element instead of allowing for as many
elements as you want with the <code>ArrayVec</code> (by just change the length value). Of
course, if you don't know how many things you'll be passing at compile time (for
whatever reason) you can also use a normal <code>Vec</code> (we're trying to avoid
allocations as much as we can though!).</p>
<a class="header" href="#update-the-vertex-shader" id="update-the-vertex-shader"><h2>Update The Vertex Shader</h2></a>
<p>We adjust the vertex shader slightly so that it passes the UV coordinates on through.</p>
<pre><code class="language-glsl">#version 450
layout (location = 0) in vec2 position;
layout (location = 1) in vec3 color;
layout (location = 2) in vec2 vert_uv;

layout (location = 0) out gl_PerVertex {
  vec4 gl_Position;
};
layout (location = 1) out vec3 frag_color;
layout (location = 2) out vec2 frag_uv;

void main()
{
  gl_Position = vec4(position, 0.0, 1.0);
  frag_color = color;
  frag_uv = vert_uv;
}
</code></pre>
<a class="header" href="#update-the-fragment-shader" id="update-the-fragment-shader"><h2>Update The Fragment Shader</h2></a>
<p>LAST STEP!</p>
<p>In the fragment shader we need to declare that we'll be getting this image data:</p>
<pre><code class="language-glsl">layout(set = 0, binding = 0) uniform texture2D tex;
layout(set = 0, binding = 1) uniform sampler samp;
</code></pre>
<p>Notice the <code>binding</code>s here match up with what we put all the way back in our
<code>DescriptorSetLayout</code>. The <code>set</code> value is matched up with the position of the
<code>DescriptorSet</code> within the <code>IntoIterator</code> that we passed to
<code>bind_graphics_descriptor_sets</code>.</p>
<p>Then in <code>main</code> we form a <code>sampler2D</code> from the <code>texture2D</code> and <code>sampler</code> put
together. This lets us call the
<a href="https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/texture.xhtml">texture</a>
function, passing the <code>sampler2D</code> as well as the UV coordinates of that
fragment. That finally ets us a RGBA color out of the texture data.</p>
<p>We could output this directly, but just for fun (and to show off a little more
of what a fragment shader can do) we'll use the time value to shift between the
texture data and the rainbow color data. This is a snap to do with the
<a href="https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/mix.xhtml">mix</a>
function. It takes two colors, and a portion (from 0.0 to 1.0) for how much the
<em>second</em> color should determine the output (it's just a linear interpolation, if
you remember that from the sampler stuff above). We'll cover this in more detail
later on. For now it's okay to just know that it works.</p>
<pre><code class="language-glsl">#version 450
layout (push_constant) uniform PushConsts {
  float time;
} push;

layout(set = 0, binding = 0) uniform texture2D tex;
layout(set = 0, binding = 1) uniform sampler samp;

layout (location = 1) in vec3 frag_color;
layout (location = 2) in vec2 frag_uv;

layout (location = 0) out vec4 color;

void main()
{
  float time01 = -0.9 * abs(sin(push.time * 0.7)) + 0.9;
  vec4 tex_color = texture(sampler2D(tex, samp), frag_uv);
  color = mix(tex_color, vec4(frag_color, 1.0), time01);
}
</code></pre>
<p>And we're finally through!</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
